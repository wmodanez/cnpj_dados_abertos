# Processador de Dados CNPJ üè¢

Este projeto automatiza o download, processamento e armazenamento dos dados p√∫blicos de CNPJ disponibilizados pela Receita Federal. Ele foi desenvolvido para ser eficiente, resiliente, modular e f√°cil de usar.

## Navega√ß√£o

<details>
  <summary>üöÄ Como Usar</summary>
  
  - [Como Usar](#-como-usar)
  - [Pr√©-requisitos](#pr√©-requisitos)
  - [Instala√ß√£o](#instala√ß√£o)
  - [Execu√ß√£o](#execu√ß√£o)
  - [Gerenciamento de Cache](#gerenciamento-de-cache)
  - [O que o Script Faz](#-o-que-o-script-faz)
</details>

<details>
  <summary>üìã Fluxo do Processo</summary>
  
  - [Fluxo do Processo](#-fluxo-do-processo)
  - [Fluxo Modular Atual (--step)](#fluxo-modular-atual---step)
  - [Ferramentas Utilizadas](#ferramentas-utilizadas)
</details>

<details>
  <summary>‚ú® Caracter√≠sticas</summary>
  
  - [Caracter√≠sticas](#-caracter√≠sticas)
</details>

<details>
  <summary>üìã Sugest√µes de Otimiza√ß√£o (Hist√≥rico)</summary>
  
  - [Sugest√µes de Otimiza√ß√£o (Hist√≥rico)](#-sugest√µes-de-otimiza√ß√£o-hist√≥rico)
  - [1. Paraleliza√ß√£o e Desempenho](#1-paraleliza√ß√£o-e-desempenho)
  - [2. Migra√ß√£o Completa para Dask](#2-migra√ß√£o-completa-para-dask)
  - [3. Otimiza√ß√µes do Dask](#3-otimiza√ß√µes-do-dask)
  - [4. Resili√™ncia e Monitoramento](#4-resili√™ncia-e-monitoramento)
  - [5. Arquitetura Geral](#5-arquitetura-geral)
</details>

<details>
  <summary>üìä Compara√ß√£o e Implementa√ß√£o (Hist√≥rico)</summary>
  
  - [Compara√ß√£o de Tecnologias](#-compara√ß√£o-de-tecnologias)
  - [Plano de Implementa√ß√£o Progressiva](#-plano-de-implementa√ß√£o-progressiva)
  - [Diagrama de Gantt do Plano de Implementa√ß√£o](#diagrama-de-gantt-do-plano-de-implementa√ß√£o)
  - [Tabela de Implementa√ß√£o das Branches](#tabela-de-implementa√ß√£o-das-branches)
</details>

<details>
  <summary>üìù Monitoramento e Configura√ß√£o</summary>
  
  - [Logs e Monitoramento](#-logs-e-monitoramento)
  - [Configura√ß√µes](#Ô∏è-configura√ß√µes)
</details>

<details>
  <summary>‚ö° Otimiza√ß√µes de Processamento</summary>
  
  - [Otimiza√ß√µes de Processamento](#otimiza√ß√µes-de-processamento)
  - [Processamento sequencial de arquivos ZIP](#processamento-sequencial-de-arquivos-zip)
  - [Sistema de Cache para Downloads](#sistema-de-cache-para-downloads)
  - [Paraleliza√ß√£o do Processamento de CSV](#paraleliza√ß√£o-do-processamento-de-csv)
  - [Tratamento Espec√≠fico de Exce√ß√µes](#tratamento-espec√≠fico-de-exce√ß√µes)
  - [Verifica√ß√µes de Seguran√ßa](#verifica√ß√µes-de-seguran√ßa)
  - [Limpeza de arquivos tempor√°rios](#limpeza-de-arquivos-tempor√°rios)
  - [Melhorias na Convers√£o de Tipos](#melhorias-na-convers√£o-de-tipos)
</details>

<details>
  <summary>ü§ù Contribui√ß√£o e Licen√ßa</summary>
  
  - [Contribuindo](#-contribuindo)
  - [Licen√ßa](#-licen√ßa)
  - [Notas](#Ô∏è-notas)
</details>

## üöÄ Como Usar

### Pr√©-requisitos

- Python 3.8 ou superior
- Espa√ßo em disco suficiente para os arquivos
- Conex√£o com internet est√°vel

### Instala√ß√£o

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/seu-usuario/cnpj.git
cd cnpj
```

2. **Crie um ambiente virtual**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

4. **Configure o ambiente**
   - Copie o arquivo `.env.local.example` para `.env.local`
   - Ajuste as configura√ß√µes conforme necess√°rio:
```env
# URL base dos dados da Receita Federal
URL_ORIGIN=https://dados.rfb.gov.br/CNPJ/

# Diret√≥rios para download e processamento
PATH_ZIP=./download/      # Arquivos ZIP baixados
PATH_UNZIP=./unzip/      # Arquivos extra√≠dos
PATH_PARQUET=./parquet/  # Arquivos Parquet processados

# Configura√ß√µes do banco de dados
FILE_DB_PARQUET=cnpj.duckdb
PATH_REMOTE_PARQUET=//servidor/compartilhado/
```

### Execu√ß√£o

O script principal `main.py` aceita diversos argumentos para customizar a execu√ß√£o. O argumento principal para controle de fluxo √© `--step`.

```bash
# 1. Execu√ß√£o completa (padr√£o: baixa, processa com Polars, cria DuckDB):
python main.py
# Equivalente a:
python main.py --step all --engine polars

# 2. Execu√ß√£o completa usando Pandas:
python main.py --step all --engine pandas

# 3. Execu√ß√£o completa usando Dask:
python main.py --step all --engine dask

# 4. Apenas baixar os arquivos ZIP mais recentes (todos os tipos):
python main.py --step download

# 5. Apenas baixar arquivos ZIP de Empresas e S√≥cios:
python main.py --step download --tipos empresas socios

# 6. Apenas processar ZIPs existentes para Parquet:
#    (Necess√°rio especificar a pasta de origem dos ZIPs e a subpasta de sa√≠da Parquet)
python main.py --step process --source-zip-folder ../dados-abertos-zip --output-subfolder meu_processamento_manual --engine polars

# 7. Apenas processar ZIPs existentes de Simples e S√≥cios usando Dask:
python main.py --step process --source-zip-folder "D:/MeusDownloads/CNPJ_ZIPs" --output-subfolder simples_socios_dask --tipos simples socios --engine dask

# 8. Apenas criar/atualizar o banco DuckDB a partir de Parquets existentes:
#    (Necess√°rio especificar a subpasta onde os Parquets est√£o)
python main.py --step database --output-subfolder meu_processamento_manual

# 9. Processar Empresas com Polars, criando subset 'empresa_privada':
#    (Execu√ß√£o completa, mas poderia ser --step process se os ZIPs j√° existirem)
python main.py --step all --tipos empresas --engine polars --output-subfolder apenas_empresas_polars --criar-empresa-privada

# 10. Processar Estabelecimentos com Polars, criando subset para SP:
#     (Execu√ß√£o completa, mas poderia ser --step process se os ZIPs j√° existirem)
python main.py --step all --tipos estabelecimentos --engine polars --output-subfolder process_sp --criar-subset-uf SP
```

**Argumentos Principais:**

*   `--step {download,process,database,all}`: Define qual(is) etapa(s) executar (padr√£o: `all`).
*   `--engine {pandas,dask,polars}`: Escolhe o motor de processamento para a etapa `process` (padr√£o: `polars`).
*   `--tipos {empresas,estabelecimentos,simples,socios}`: Filtra quais tipos de dados baixar ou processar (padr√£o: todos).
*   `--source-zip-folder <caminho>`: Pasta de origem dos arquivos ZIP (obrigat√≥rio para `--step process`).
*   `--output-subfolder <nome>`: Subpasta em `PATH_PARQUET` para salvar/ler Parquets (obrigat√≥rio para `--step process` e `--step database`).
*   `--criar-empresa-privada`: Flag para criar subset de empresas privadas (na etapa `process`).
*   `--criar-subset-uf <UF>`: Flag para criar subset de estabelecimentos por UF (na etapa `process`).
*   `--log-level <N√çVEL>`: Ajusta o n√≠vel de log (padr√£o: `INFO`).

### Gerenciamento de Cache

```bash
# Exibir informa√ß√µes sobre arquivos em cache
python -m src.cache_manager cache-info

# Limpar o cache de downloads
python -m src.cache_manager clear-cache
```

### Benchmarks

O projeto inclui scripts de benchmark para comparar o desempenho de diferentes bibliotecas (Pandas, Dask, Polars) no processamento dos dados:

```bash
# Benchmark para dados de Empresas
python benchmark/benchmark_empresa.py --completo --path_zip dados-abertos-zip

# Benchmark para dados do Simples Nacional
python benchmark/benchmark_simples.py --completo --path_zip dados-abertos-zip

# Benchmark para dados de Estabelecimentos (Exemplo)
python benchmark/benchmark_estabelecimento.py
```

**Observa√ß√£o:** Os benchmarks utilizam um sistema de **pontua√ß√£o ponderada** para determinar o m√©todo mais adequado, considerando diferentes m√©tricas de desempenho com pesos espec√≠ficos (ex: Tempo Total peso 5, Espa√ßo em Disco peso 4, etc.). Os resultados detalhados e a pontua√ß√£o s√£o exibidos no relat√≥rio final.

## üìä O que o Script Faz

O script `main.py` orquestra um fluxo modular que pode ser executado em etapas:

1.  **Download dos Dados (`--step download` ou `all`)**
    *   Identifica os arquivos ZIP mais recentes no portal da Receita Federal.
    *   Baixa os arquivos necess√°rios (considerando os tipos especificados) de forma ass√≠ncrona e paralela.
    *   Utiliza cache para evitar downloads repetidos.
    *   Verifica a integridade b√°sica dos arquivos baixados.

2.  **Processamento para Parquet (`--step process` ou `all`)**
    *   L√™ arquivos ZIP de uma pasta de origem (`--source-zip-folder`).
    *   Extrai o conte√∫do de cada ZIP para uma subpasta tempor√°ria.
    *   Processa os arquivos de dados (CSV ou similar) usando o engine selecionado (`--engine`).
        *   Aplica transforma√ß√µes (renomea√ß√£o, convers√£o de tipos, etc.).
        *   Gera arquivos Parquet otimizados e particionados na subpasta de sa√≠da (`--output-subfolder`).
        *   Cria subsets opcionais (`--criar-empresa-privada`, `--criar-subset-uf`).
    *   Limpa as subpastas tempor√°rias.

3.  **Cria√ß√£o do Banco de Dados (`--step database` ou `all`)**
    *   L√™ os arquivos Parquet de uma subpasta especificada (`--output-subfolder`).
    *   Cria ou atualiza um arquivo de banco de dados DuckDB (`cnpj.duckdb` por padr√£o).
    *   Cria tabelas no DuckDB para cada tipo de dado encontrado (empresas, estabelecimentos, socios, simples, e tabelas auxiliares como cnae, municipio, etc., se presentes na pasta `base`).
    *   Opcionalmente, faz backup do banco para um local remoto.

## üìã Fluxo do Processo

### Fluxo Modular Atual (`--step`)

O fluxo de execu√ß√£o agora √© controlado pelo argumento `--step`, permitindo executar partes espec√≠ficas do processo:

```mermaid
graph TD
    A[In√≠cio: main.py --step <valor>] --> Args{An√°lise dos Argumentos}
    
    Args --> Step{Qual --step?}
    
    Step -->|download| D[Etapa Download]
    Step -->|process| P_Prep[Prepara Caminhos para Processamento]
    Step -->|database| DB_Prep[Prepara Caminhos para Database]
    Step -->|all| D
    
    D --> D_End{Fim se --step download}
    D_End -- Sim --> Z[Fim]
    D_End -- N√£o (step all) --> P_Prep
    
    P_Prep --> Engine{Engine Dask?}
    Engine -- Sim --> DaskInitP[Inicia Dask]
    Engine -- N√£o --> P[Etapa Processamento Parquet]
    DaskInitP --> P
    
    P --> P_End{Fim se --step process}
    P_End -- Sim --> DaskEndP[Encerra Dask se iniciado]
    P_End -- N√£o (step all) --> DB_Prep
    DaskEndP --> Z
    
    DB_Prep --> EngineDB{Engine Dask?}
    EngineDB -- Sim --> DaskInitDB[Inicia Dask (se n√£o j√° iniciado)]
    EngineDB -- N√£o --> DB[Etapa Cria√ß√£o DuckDB]
    DaskInitDB --> DB
    
    DB --> DB_End{Fim se --step database}
    DB_End -- Sim --> DaskEndDB[Encerra Dask se iniciado]
    DB_End -- N√£o (step all) --> DaskEndAll[Encerra Dask se iniciado]
    DaskEndDB --> Z
    DaskEndAll --> Z
    
    classDef etapa fill:#cfe2ff,stroke:#084298,stroke-width:2px;
    classDef decisao fill:#fff3cd,stroke:#856404,stroke-width:1px
    classDef prep fill:#e2e3e5,stroke:#495057,stroke-width:1px
    classDef end fill:#f8d7da,stroke:#842029,stroke-width:1px

    class A,Z end
    class D,P,DB etapa
    class Args,Step,D_End,P_End,DB_End,Engine,EngineDB decisao
    class P_Prep,DB_Prep,DaskInitP,DaskEndP,DaskInitDB,DaskEndDB,DaskEndAll prep

```

**Legenda:**

*   **Ret√¢ngulos Azuis:** Etapas principais do fluxo.
*   **Losangos Amarelos:** Decis√µes baseadas nos argumentos ou no estado.
*   **Ret√¢ngulos Cinzas:** Prepara√ß√£o de caminhos ou inicializa√ß√£o/encerramento de Dask.
*   **Ret√¢ngulos Vermelhos:** Pontos de in√≠cio e fim.

### Ferramentas Utilizadas

*   **Processamento:** Pandas, Dask, Polars (selecion√°vel via `--engine`)
*   **Download Ass√≠ncrono:** asyncio, aiohttp
*   **Banco de Dados:** DuckDB
*   **Manipula√ß√£o de Arquivos:** zipfile, os, shutil
*   **Linha de Comando:** argparse
*   **Logging:** logging, RichHandler
*   **Configura√ß√£o:** python-dotenv
*   **Utilit√°rios:** NumPy, Rich (para progresso)

## ‚ú® Caracter√≠sticas

*   **Execu√ß√£o Modular:** Controle granular do fluxo com `--step` (`download`, `process`, `database`, `all`).
*   **Multi-Engine:** Suporte padronizado para Pandas, Dask e Polars (`--engine`), com Polars como padr√£o.
*   **Download Eficiente:** Ass√≠ncrono, paralelo, com cache e retentativas.
*   **Processamento Padronizado:** L√≥gica de extra√ß√£o, transforma√ß√£o e salvamento consistente entre os engines.
*   **Sa√≠da Otimizada:** Arquivos Parquet particionados e banco DuckDB consolidado.
*   **Configurabilidade:** Vari√°veis de ambiente (`.env.local`) e argumentos de linha de comando.
*   **Subsets Opcionais:** Cria√ß√£o de subsets por UF (`--criar-subset-uf`) ou para empresas privadas (`--criar-empresa-privada`).
*   **Logging Detalhado:** Logs em arquivo e console formatado com Rich.

## üîÑ Atualiza√ß√µes Recentes

*   **(Julho/2024)** Implementada execu√ß√£o modular com argumento `--step` (download, process, database, all), substituindo `--skip-download` e `--skip-processing`.
*   **(Julho/2024)** Padronizadas as implementa√ß√µes Pandas, Dask e Polars para todos os tipos de dados (Empresas, Estabelecimentos, Simples, S√≥cios).
*   **(Julho/2024)** Polars definido como o engine de processamento padr√£o (`--engine polars`).
*   **(Julho/2024)** Adicionada a flag `--criar-subset-uf` para gerar um Parquet separado com estabelecimentos de uma UF espec√≠fica.
*   **(Julho/2024)** Corrigida a l√≥gica de busca da pasta `base` na cria√ß√£o do DuckDB.
*   **(Julho/2024)** Refatora√ß√£o do fluxo Dask para melhor alinhamento com os outros engines.

## üìã Sugest√µes de Otimiza√ß√£o (Hist√≥rico)

### 1. Paraleliza√ß√£o e Desempenho

#### Downloads Ass√≠ncronos
- Implementar downloads paralelos com `asyncio` e `aiohttp`
- Redu√ß√£o de 60-80% no tempo de download total
- Funciona em conjunto com o cache de metadados

```bash
# Criar branch para implementa√ß√£o de downloads ass√≠ncronos
git checkout -b feature/async-downloads master
```

#### Descompacta√ß√£o em Paralelo
- Usar `concurrent.futures` para extrair m√∫ltiplos arquivos simultaneamente
- Redu√ß√£o significativa no tempo de extra√ß√£o

```bash
# Criar branch para implementa√ß√£o de descompacta√ß√£o paralela
git checkout -b feature/parallel-extraction master
```

#### Cache de Metadados

- Implementar cache de metadados (SQLite ou arquivo JSON)
- Evitar reprocessamento desnecess√°rio, processando apenas o que mudou

```bash
# Criar branch para implementa√ß√£o do cache de metadados
git checkout -b feature/metadata-cache master
```

### 2. Migra√ß√£o Completa para Dask

#### Substitui√ß√£o de Pandas por Dask
- Identificar todas as partes do c√≥digo que usam Pandas diretamente
- Converter opera√ß√µes Pandas para suas equivalentes em Dask
- Garantir que toda a pipeline de dados aproveite o processamento paralelo

```bash
# Criar branch para migra√ß√£o completa para Dask
git checkout -b feature/pandas-to-dask master
```

#### Refatora√ß√£o de C√≥digo para Processamento Lazy
- Implementar padr√µes de processamento lazy/tardio
- Evitar materializa√ß√£o desnecess√°ria de DataFrames
- Otimizar cadeia de transforma√ß√µes

```bash
# Criar branch para refatora√ß√£o para processamento lazy
git checkout -b feature/lazy-processing master
```

### 3. Otimiza√ß√µes do Dask

#### Otimiza√ß√£o do Dask
- Melhorar a configura√ß√£o e utiliza√ß√£o do Dask
- Implementar particionamento otimizado
- Utilizar funcionalidades avan√ßadas como Dask Bag para processamento inicial

```bash
# Criar branch para otimiza√ß√£o do Dask
git checkout -b feature/dask-optimization master
```

#### Formato de Armazenamento Otimizado

- Otimiza√ß√£o avan√ßada do Parquet com compress√£o e estat√≠sticas
- Melhoria de esquemas e particionamento de dados
- Implementa√ß√£o de caching de resultados intermedi√°rios

```bash
# Criar branch para implementa√ß√£o de armazenamento otimizado
git checkout -b feature/optimized-storage master
```

#### Valida√ß√£o de Dados Integrada

- Implementar valida√ß√£o integrada ao fluxo de processamento
- Esquemas de valida√ß√£o para cada tipo de dados
- Corre√ß√£o autom√°tica de problemas comuns

```bash
# Criar branch para implementa√ß√£o de valida√ß√£o de dados integrada
git checkout -b feature/integrated-validation master
```

### 4. Resili√™ncia e Monitoramento

#### Checkpoints de Recupera√ß√£o

- Implementar sistema de checkpoints para recupera√ß√£o de falhas
- Capacidade de retomar de falhas sem reprocessamento completo

```bash
# Criar branch para implementa√ß√£o de checkpoints de recupera√ß√£o
git checkout -b feature/recovery-checkpoints master
```

#### Sistema de Monitoramento

- Melhorar a integra√ß√£o com dashboard Dask
- Adicionar m√©tricas e monitoramento avan√ßado
- Integra√ß√£o com sistemas de observabilidade

```bash
# Criar branch para implementa√ß√£o do sistema de monitoramento
git checkout -b feature/monitoring-system master
```

#### Tratamento Avan√ßado de Erros

- Melhorar o sistema de tratamento de erros
- Logging detalhado com categoriza√ß√£o de problemas
- Estrat√©gias de recupera√ß√£o por tipo de erro

```bash
# Criar branch para implementa√ß√£o de tratamento avan√ßado de erros
git checkout -b feature/advanced-error-handling master
```

### 5. Arquitetura Geral

#### Pipeline Modular

- Arquitetura em etapas independentes
- Facilidade de manuten√ß√£o e possibilidade de executar apenas partes espec√≠ficas

```bash
# Criar branch para implementa√ß√£o de pipeline modular
git checkout -b feature/modular-pipeline master
```

#### Integra√ß√£o Avan√ßada com DuckDB

- Melhorar a integra√ß√£o entre Dask e DuckDB
- Otimiza√ß√£o de querys e carregamento
- Cria√ß√£o de visualiza√ß√µes anal√≠ticas

```bash
# Criar branch para implementa√ß√£o de integra√ß√£o com DuckDB
git checkout -b feature/duckdb-integration master
```

## üìä Compara√ß√£o e Implementa√ß√£o (Hist√≥rico)

| Aspecto | Atual | Sugest√£o de Otimiza√ß√£o | Benef√≠cio |
|---------|-------|----------|-----------|
| Processamento Distribu√≠do | Dask b√°sico com Pandas em algumas partes | Dask completo com particionamento adequado | Maior velocidade de processamento e uso eficiente de recursos |
| Formato de Armazenamento | Parquet b√°sico via Dask | Parquet otimizado com estat√≠sticas e compress√£o | Melhor compress√£o e desempenho de leitura |
| Download de Arquivos | PyCurl sequencial | asyncio/aiohttp paralelo | Redu√ß√£o de 60-80% no tempo de download |
| Descompacta√ß√£o | zipfile sequencial | concurrent.futures paralelo | Redu√ß√£o significativa no tempo de extra√ß√£o |
| Valida√ß√£o de Dados | M√≠nima | Sistema integrado de valida√ß√£o | Maior qualidade dos dados e robustez |
| Recupera√ß√£o de Falhas | Inexistente | Sistema de checkpoints para retomada | Continuidade em caso de interrup√ß√µes |
| Monitoramento | Logs b√°sicos | Dashboard Dask aprimorado + m√©tricas | Melhor observabilidade |

## üìÖ Plano de Implementa√ß√£o Progressiva

Para implementar estas melhorias de forma gradual e segura:

### Fase 1: Otimiza√ß√µes Imediatas (1-2 semanas)

- Implementar downloads paralelos com asyncio
- Adicionar descompacta√ß√£o em paralelo
- Implementar cache b√°sico de metadados

### Fase 2: Migra√ß√£o Completa para Dask (2-3 semanas)

- Identificar e substituir opera√ß√µes Pandas por Dask
- Refatorar c√≥digo para processamento lazy
- Implementar padr√µes de processamento distribu√≠do em toda a pipeline

### Fase 3: Otimiza√ß√£o do Dask (2-3 semanas)

- Configurar particionamento otimizado do Dask
- Melhorar utiliza√ß√£o de recursos
- Implementar valida√ß√£o de dados integrada

### Fase 4: Otimiza√ß√£o de Fluxo (2-3 semanas)

- Implementar sistema de corre√ß√£o de dados
- Adicionar sistema de checkpoints
- Otimizar armazenamento Parquet

### Fase 5: Refinamentos Finais (1-2 semanas)

- Implementar integra√ß√£o avan√ßada com DuckDB
- Configurar monitoramento e m√©tricas
- Testes de desempenho e ajustes finais


### Tabela de Implementa√ß√£o das Branches

| Fase | Nome da Branch              | Descri√ß√£o                               | Data In√≠cio | Data Previs√£o | Data Conclus√£o | Status | Depend√™ncias |
| :--- | :-------------------------- | :-------------------------------------- | :---------- | :------------ | :------------- | :----- | :--------- |
| 1    | feature/async-downloads     | Implementa√ß√£o de downloads ass√≠ncronos  | 10/04/2025  | 15/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 1    | feature/parallel-extraction | Descompacta√ß√£o em paralelo de arquivos  | 09/04/2025  | 14/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 1    | feature/metadata-cache      | Sistema de cache de metadados           | 15/04/2025  | 24/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 2    | feature/pandas-to-dask      | Migra√ß√£o de opera√ß√µes Pandas para Dask  | 25/04/2025  | 05/05/2025    | -              | ‚è≥     | -            |
| 2    | feature/lazy-processing     | Refatora√ß√£o para processamento lazy     | 06/05/2025  | 15/05/2025    | -              | ‚è≥     | feature/pandas-to-dask |
| 3    | feature/dask-optimization   | Otimiza√ß√£o do Dask e particionamento    | 16/05/2025  | 25/05/2025    | -              | ‚è≥     | feature/lazy-processing |
| 3    | feature/optimized-storage   | Otimiza√ß√£o do formato de armazenamento  | 26/05/2025  | 02/06/2025    | -              | ‚è≥     | feature/dask-optimization |
| 3    | feature/integrated-validation | Valida√ß√£o integrada de dados  | 03/06/2025  | 10/06/2025    | -              | ‚è≥     | feature/dask-optimization |
| 4    | feature/recovery-checkpoints| Sistema de checkpoints para recupera√ß√£o | 11/06/2025  | 18/06/2025    | -              | ‚è≥     | feature/integrated-validation |
| 4    | feature/advanced-error-handling| Tratamento avan√ßado de erros         | 11/06/2025  | 18/06/2025    | -              | ‚è≥     | feature/integrated-validation |
| 4    | feature/monitoring-system   | Implementa√ß√£o de sistema de monitoramento| 19/06/2025  | 26/06/2025    | -              | ‚è≥     | feature/recovery-checkpoints |
| 5    | feature/modular-pipeline    | Implementa√ß√£o de pipeline modular       | 27/06/2025  | 04/07/2025    | -              | ‚è≥     | feature/monitoring-system |
| 5    | feature/duckdb-integration  | Integra√ß√£o avan√ßada com DuckDB          | 27/06/2025  | 04/07/2025    | -              | ‚è≥     | feature/monitoring-system |

### Diagrama de Gantt do Plano de Implementa√ß√£o

O diagrama abaixo ilustra a programa√ß√£o temporal das tarefas, suas interdepend√™ncias e o caminho cr√≠tico do projeto de otimiza√ß√£o:

```mermaid
gantt
    title Cronograma de Implementa√ß√£o das Otimiza√ß√µes do Fluxo CNPJ
    dateFormat  YYYY-MM-DD
    axisFormat %d/%m
    excludes weekends 2025-04-17 2025-04-18 2025-04-21 2025-05-01 2025-05-02 2025-06-19 2025-06-20
    
    %% Feriados brasileiros e pontos facultativos
    section Dias N√£o √öteis
    Ponto Facultativo (antes da Paix√£o)       :crit, active, holiday0a, 2025-04-17, 1d
    Sexta-feira da Paix√£o                    :crit, active, holiday0, 2025-04-18, 1d
    Tiradentes                               :crit, active, holiday1, 2025-04-21, 1d
    Dia do Trabalho                          :crit, active, holiday2, 2025-05-01, 1d
    Ponto Facultativo (ap√≥s Dia do Trabalho) :crit, active, holiday2b, 2025-05-02, 1d
    Corpus Christi                           :crit, active, holiday3, 2025-06-19, 1d
    Ponto Facultativo (ap√≥s Corpus Christi)  :crit, active, holiday3b, 2025-06-20, 1d
    
    section Fase 1: Otimiza√ß√µes Imediatas
    An√°lise inicial e planejamento detalhado    :a1, 2025-04-14, 3d
    Implementar downloads paralelos com asyncio  :a2, after a1, 4d
    Adicionar descompacta√ß√£o em paralelo        :a3, after a1, 4d
    Implementar cache b√°sico de metadados       :a4, after a2 a3, 5d
    Testes de performance da Fase 1             :a5, after a4, 2d
    
    section Fase 2: Migra√ß√£o Completa para Dask
    Identificar e substituir opera√ß√µes Pandas    :b1, after a5, 7d
    Refatorar para processamento lazy            :b2, after b1, 6d
    Testes de compatibilidade                    :b3, after b2, 3d
    
    section Fase 3: Otimiza√ß√£o do Dask
    Configurar particionamento otimizado        :c1, after b3, 5d
    Melhorar utiliza√ß√£o de recursos             :c2, after c1, 3d
    Implementar valida√ß√£o de dados integrada    :c3, after c2, 5d
    Testes de otimiza√ß√£o do Dask                :c4, after c3, 3d
    
    section Fase 4: Otimiza√ß√£o de Fluxo
    Implementar sistema de corre√ß√£o de dados    :d1, after c4, 5d
    Adicionar sistema de checkpoints            :d2, after d1, 4d
    Otimizar armazenamento Parquet              :d3, after d1, 5d
    Testes de carga do fluxo completo           :d4, after d2 d3, 3d
    
    section Fase 5: Refinamentos Finais
    Implementar integra√ß√£o avan√ßada com DuckDB  :e1, after d4, 4d
    Configurar monitoramento e m√©tricas         :e2, after d4, 4d
    Testes finais de desempenho                 :e3, after e1 e2, 3d
    Documenta√ß√£o e treinamento                  :e4, after e3, 2d
```

O diagrama acima representa:

- **Dura√ß√£o das tarefas**: Cada barra representa uma tarefa com sua dura√ß√£o estimada
- **Depend√™ncias**: As tarefas conectadas mostram quais precisam ser conclu√≠das antes de outras come√ßarem
- **Agrupamento**: As tarefas est√£o organizadas nas cinco fases do plano de implementa√ß√£o
- **Caminho cr√≠tico**: A sequ√™ncia de tarefas que determina a dura√ß√£o total do projeto

Este cronograma prev√™ aproximadamente 12-14 semanas para a implementa√ß√£o completa, considerando as depend√™ncias entre tarefas e tempos realistas para desenvolvimento e testes.

## Otimiza√ß√µes de Processamento

Este projeto foi otimizado para lidar com grandes volumes de dados de maneira eficiente. 
As seguintes otimiza√ß√µes foram implementadas:

### Processamento sequencial de arquivos ZIP

Em vez de descompactar todos os arquivos de uma vez (o que poderia consumir muito espa√ßo em disco), 
o processamento agora √© feito sequencialmente:

1. Cada arquivo ZIP √© descompactado individualmente
2. Os arquivos CSV resultantes s√£o processados em paralelo
3. Os arquivos tempor√°rios s√£o exclu√≠dos imediatamente
4. S√≥ ent√£o o pr√≥ximo arquivo ZIP √© processado

Essa abordagem tem as seguintes vantagens:
- Reduz significativamente o uso de espa√ßo em disco
- Previne vazamentos de mem√≥ria durante o processamento
- Mant√©m o diret√≥rio de trabalho limpo
- Permite processamento de conjuntos de dados maiores sem esgotar o armazenamento

### Sistema de Cache para Downloads

- Evita baixar novamente arquivos j√° processados recentemente
- Configur√°vel via par√¢metros de tempo de expira√ß√£o
- Fornece comandos para gerenciar o cache (visualizar informa√ß√µes e limpar)

### Paraleliza√ß√£o do Processamento de CSV

- Os arquivos CSV dentro de cada ZIP s√£o processados em paralelo
- Utiliza ThreadPoolExecutor e Dask para processamento eficiente
- N√∫mero de workers configur√°vel via `config.dask.n_workers`

### Tratamento Espec√≠fico de Exce√ß√µes

- Implementado tratamento espec√≠fico para diferentes tipos de exce√ß√µes
- Mensagens de erro detalhadas para facilitar a depura√ß√£o
- Melhor robustez e recupera√ß√£o de falhas

### Verifica√ß√µes de Seguran√ßa

- Verifica√ß√£o de espa√ßo em disco antes de iniciar o processamento
- Verifica√ß√£o de espa√ßo antes de descompactar cada arquivo ZIP
- Verifica√ß√£o de conex√£o com a internet antes de iniciar downloads
- Estimativa do tamanho de arquivos ap√≥s descompacta√ß√£o

### Limpeza de arquivos tempor√°rios

Todos os arquivos tempor√°rios descompactados s√£o exclu√≠dos ap√≥s o processamento, mesmo em caso de erro,
garantindo que n√£o fiquem arquivos residuais no sistema.

### Melhorias na Convers√£o de Tipos

- **Tratamento robusto para valores num√©ricos**: Convers√£o segura para Int64 com suporte para valores nulos
- **Convers√£o avan√ßada de datas**: Tratamento melhorado para valores inv√°lidos (zeros, valores vazios, etc.)
- **Processamento de valores monet√°rios**: Convers√£o adequada de valores com v√≠rgulas como separador decimal
- **Valida√ß√£o de tipos ap√≥s convers√£o**: Verifica√ß√£o da integridade dos dados p√≥s-convers√£o
- **Logs detalhados**: Rastreamento do processo de convers√£o para facilitar depura√ß√£o

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ‚ö†Ô∏è Notas

- O processamento pode levar algumas horas dependendo do hardware
- Requisitos m√≠nimos de espa√ßo em disco:
  - Empresas: 5GB
  - Estabelecimentos: 8GB
  - Simples Nacional: 3GB
- Em caso de falhas, o sistema tentar√° novamente automaticamente
- Verifica√ß√£o de espa√ßo em disco √© realizada antes da descompacta√ß√£o

## üõ†Ô∏è Processamento e Regras de Neg√≥cio

Durante o processamento, v√°rias transforma√ß√µes e regras de neg√≥cio s√£o aplicadas, especialmente aos dados de Empresas:

1.  **Convers√£o de Tipos**: Colunas num√©ricas e de data s√£o convertidas para os tipos apropriados.
2.  **Renomea√ß√£o**: Algumas colunas s√£o renomeadas para maior clareza (ex: `razao_social_nome_empresarial` para `razao_social`).
3.  **Extra√ß√£o de CPF**: 
    - O CPF (Pessoa F√≠sica) √© extra√≠do da coluna `razao_social`.
    - O script busca por padr√µes formatados (`xxx.xxx.xxx-xx`) ou por sequ√™ncias de 11 d√≠gitos.
    - O CPF extra√≠do (apenas os 11 d√≠gitos) √© armazenado em uma nova coluna chamada `CPF`.
    - Esta coluna n√£o √© obrigat√≥ria, pois nem todas as raz√µes sociais conter√£o um CPF.
4.  **Limpeza da Raz√£o Social**: Ap√≥s a extra√ß√£o do CPF, o mesmo √© **removido** da coluna `razao_social` original para manter apenas o nome/raz√£o social. Espa√ßos extras s√£o removidos.

Essas transforma√ß√µes s√£o implementadas nas fun√ß√µes `apply_empresa_transformations_pandas`, `apply_empresa_transformations_polars`, e `apply_empresa_transformations_dask` dentro de `src/process/empresa.py`.

## ‚ú® Caracter√≠sticas

- **Automatizado**: Busca, baixa e processa os dados automaticamente.
- **Resiliente**: Possui retries em caso de falha no download e verifica√ß√µes de integridade.

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.

## üìú Licen√ßa

Este projeto est√° licenciado sob a [MIT License](LICENSE).

## üìù Notas

- Os dados da Receita Federal s√£o atualizados periodicamente. Execute o script regularmente para manter seus dados atualizados.
- O processamento pode exigir uma quantidade significativa de recursos (CPU, mem√≥ria, disco) dependendo do volume de dados.

---
*Desenvolvido com ‚ù§Ô∏è e Python!* 

