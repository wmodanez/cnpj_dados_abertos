# Processador de Dados CNPJ üè¢

Este projeto automatiza o download, processamento e armazenamento dos dados p√∫blicos de CNPJ disponibilizados pela Receita Federal. Ele foi desenvolvido para ser eficiente, resiliente e f√°cil de usar.

## Navega√ß√£o

<details>
  <summary>üöÄ Como Usar</summary>
  
  - [Como Usar](#-como-usar)
  - [Pr√©-requisitos](#pr√©-requisitos)
  - [Instala√ß√£o](#instala√ß√£o)
  - [Execu√ß√£o](#execu√ß√£o)
  - [Gerenciamento de Cache](#gerenciamento-de-cache)
  - [O que o Script Faz](#-o-que-o-script-faz)
</details>

<details>
  <summary>üìã Fluxo do Processo</summary>
  
  - [Fluxo do Processo](#-fluxo-do-processo)
  - [Etapas do Fluxo Atual](#etapas-do-fluxo-atual)
  - [Ferramentas Utilizadas Atualmente](#ferramentas-utilizadas-atualmente)
</details>

<details>
  <summary>‚ú® Caracter√≠sticas</summary>
  
  - [Caracter√≠sticas](#-caracter√≠sticas)
</details>

<details>
  <summary>üìã Sugest√µes de Otimiza√ß√£o</summary>
  
  - [Sugest√µes de Otimiza√ß√£o](#-sugest√µes-de-otimiza√ß√£o)
  - [1. Paraleliza√ß√£o e Desempenho](#1-paraleliza√ß√£o-e-desempenho)
  - [2. Migra√ß√£o Completa para Dask](#2-migra√ß√£o-completa-para-dask)
  - [3. Otimiza√ß√µes do Dask](#3-otimiza√ß√µes-do-dask)
  - [4. Resili√™ncia e Monitoramento](#4-resili√™ncia-e-monitoramento)
  - [5. Arquitetura Geral](#5-arquitetura-geral)
</details>

<details>
  <summary>üìä Compara√ß√£o e Implementa√ß√£o</summary>
  
  - [Compara√ß√£o de Tecnologias](#-compara√ß√£o-de-tecnologias)
  - [Plano de Implementa√ß√£o Progressiva](#-plano-de-implementa√ß√£o-progressiva)
  - [Diagrama de Gantt do Plano de Implementa√ß√£o](#diagrama-de-gantt-do-plano-de-implementa√ß√£o)
  - [Tabela de Implementa√ß√£o das Branches](#tabela-de-implementa√ß√£o-das-branches)
</details>

<details>
  <summary>üìù Monitoramento e Configura√ß√£o</summary>
  
  - [Logs e Monitoramento](#-logs-e-monitoramento)
  - [Configura√ß√µes](#Ô∏è-configura√ß√µes)
</details>

<details>
  <summary>‚ö° Otimiza√ß√µes de Processamento</summary>
  
  - [Otimiza√ß√µes de Processamento](#otimiza√ß√µes-de-processamento)
  - [Processamento sequencial de arquivos ZIP](#processamento-sequencial-de-arquivos-zip)
  - [Sistema de Cache para Downloads](#sistema-de-cache-para-downloads)
  - [Paraleliza√ß√£o do Processamento de CSV](#paraleliza√ß√£o-do-processamento-de-csv)
  - [Tratamento Espec√≠fico de Exce√ß√µes](#tratamento-espec√≠fico-de-exce√ß√µes)
  - [Verifica√ß√µes de Seguran√ßa](#verifica√ß√µes-de-seguran√ßa)
  - [Limpeza de arquivos tempor√°rios](#limpeza-de-arquivos-tempor√°rios)
  - [Melhorias na Convers√£o de Tipos](#melhorias-na-convers√£o-de-tipos)
</details>

<details>
  <summary>ü§ù Contribui√ß√£o e Licen√ßa</summary>
  
  - [Contribuindo](#-contribuindo)
  - [Licen√ßa](#-licen√ßa)
  - [Notas](#Ô∏è-notas)
</details>

## üöÄ Como Usar

### Pr√©-requisitos

- Python 3.8 ou superior
- Espa√ßo em disco suficiente para os arquivos
- Conex√£o com internet est√°vel

### Instala√ß√£o

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/seu-usuario/cnpj.git
cd cnpj
```

2. **Crie um ambiente virtual**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

4. **Configure o ambiente**
   - Copie o arquivo `.env.local.example` para `.env.local`
   - Ajuste as configura√ß√µes conforme necess√°rio:
```env
# URL base dos dados da Receita Federal
URL_ORIGIN=https://dados.rfb.gov.br/CNPJ/

# Diret√≥rios para download e processamento
PATH_ZIP=./download/      # Arquivos ZIP baixados
PATH_UNZIP=./unzip/      # Arquivos extra√≠dos
PATH_PARQUET=./parquet/  # Arquivos Parquet processados

# Configura√ß√µes do banco de dados
FILE_DB_PARQUET=cnpj.duckdb
PATH_REMOTE_PARQUET=//servidor/compartilhado/
```

### Execu√ß√£o

```bash
python main.py
```

### Gerenciamento de Cache

```bash
# Exibir informa√ß√µes sobre arquivos em cache
python -m src.cache_manager cache-info

# Limpar o cache de downloads
python -m src.cache_manager clear-cache
```

### Benchmarks

O projeto inclui scripts de benchmark para comparar o desempenho de diferentes bibliotecas (Pandas, Dask, Polars) no processamento dos dados:

```bash
# Benchmark para dados de Empresas
python benchmark/benchmark_empresa.py --completo --path_zip dados-abertos-zip

# Benchmark para dados do Simples Nacional
python benchmark/benchmark_simples.py --completo --path_zip dados-abertos-zip

# Benchmark para dados de Estabelecimentos (Exemplo)
python benchmark/benchmark_estabelecimento.py
```

**Observa√ß√£o:** Os benchmarks utilizam um sistema de **pontua√ß√£o ponderada** para determinar o m√©todo mais adequado, considerando diferentes m√©tricas de desempenho com pesos espec√≠ficos (ex: Tempo Total peso 5, Espa√ßo em Disco peso 4, etc.). Os resultados detalhados e a pontua√ß√£o s√£o exibidos no relat√≥rio final.

## üìä O que o Script Faz

1. **Download dos Dados**
   - Identifica os arquivos mais recentes
   - Baixa em paralelo com retry autom√°tico
   - Verifica integridade dos arquivos
   - Mant√©m cache para evitar downloads desnecess√°rios

2. **Processamento**
   - Verifica espa√ßo em disco e conex√£o com a internet
   - Extrai arquivos ZIP sequencialmente
   - Processa dados CSV em paralelo com Dask
   - Gera arquivos Parquet otimizados

3. **Armazenamento**
   - Cria banco de dados DuckDB
   - Organiza dados em tabelas
   - Copia para local remoto

## üìã Fluxo do Processo

O atual pipeline de processamento de dados de CNPJs segue um fluxo estruturado, mas com oportunidades de otimiza√ß√£o:

```mermaid
---
config:
   theme: neutral
   layout: elk
   elk:
      direction: DOWN
      nodeSpacing: 50
      rankSpacing: 70
      mergeEdges: true
      nodePlacementStrategy: SIMPLE
      algorithm: layered
      layered:
        alignedLayout: true
   flowchart:
      useMaxWidth: true
      curve: basis
      defaultRenderer: elk
      htmlLabels: true
      animate: true

---
flowchart TD
    %% Etapa 1: Coleta de Dados
    A[In√≠cio] --> B[Configura√ß√£o das vari√°veis]
    B --> C[Inicializa√ß√£o do Dask Cluster]
    C --> D[Busca URL mais recente]
    
    %% Verifica√ß√£o inicial de novos dados
    D --> N{Novos dados dispon√≠veis?}
    N -->|N√£o| Q[Fim]
    
    %% Etapa 2: Download e Descompacta√ß√£o
    N -->|Sim| E{Loop por tipos de dados}
    E --> F[Download dos arquivos ZIP com PyCurl]
    F --> G[Descompacta√ß√£o com zipfile]
    
    %% Etapa 3: Processamento com Dask
    G --> H[Leitura dos CSV com Dask DataFrame]
    H --> I[Transforma√ß√£o e limpeza]
    
    %% Etapa 4: Segmenta√ß√£o de dados
    I --> J[Processamento espec√≠fico do tipo de dado]
    
    %% Etapa 5: Armazenamento em Parquet
    J --> K[Convers√£o para Parquet]
    
    %% Pr√≥ximo tipo de dado ou finaliza√ß√£o
    K --> L{Mais tipos?}
    L -->|Sim| E
    
    %% Consolida√ß√£o dos arquivos Parquet em DuckDB
    L -->|N√£o| R[Leitura e verifica√ß√£o dos arquivos Parquet com Python/Pandas]
    R --> S{Existem arquivos Parquet suficientes?}
    S -->|Sim| O[Consolida√ß√£o dos Parquets em um banco DuckDB]
    S -->|N√£o| P
    
    %% Finaliza√ß√£o
    O --> P[Encerramento do cliente Dask]
    P --> Q
    
    %% Estilos
    classDef ferramenta fill:#f9f,stroke:#333,stroke-width:2px
    classDef process fill:#bbf,stroke:#333,stroke-width:1px
    classDef decision fill:#fbb,stroke:#333,stroke-width:1px
    
    class C,F,G,H,I,J,K,O,R ferramenta
    class B,D,P process
    class E,L,N,S decision
    
    %% Anima√ß√£o das setas
    linkStyle default stroke:#00AA00,stroke-width:2px,color:green,animation:flowing 1.5s linear infinite,stroke-dasharray:5,2,3,2
```

### Etapas do Fluxo Atual

1. **Configura√ß√£o e Inicializa√ß√£o**
   - Carregamento de vari√°veis de ambiente com `dotenv`
   - Inicializa√ß√£o do cluster `Dask` para processamento distribu√≠do
   - Configura√ß√£o de logging para acompanhamento do processo

2. **Obten√ß√£o e Extra√ß√£o dos Dados**
   - Uso de `requests` e `BeautifulSoup` para identificar URLs mais recentes
   - Download sequencial de arquivos ZIP usando `PyCurl`
   - Extra√ß√£o dos arquivos com o m√≥dulo `zipfile` do Python

3. **Processamento dos Dados**
   - Leitura dos CSVs extra√≠dos utilizando `Dask DataFrame`
   - Processamento separado para cada tipo de dado (Empresas, Estabelecimentos, Simples, S√≥cios)
   - Transforma√ß√µes e limpezas espec√≠ficas para cada conjunto

4. **Armazenamento Intermedi√°rio**
   - Convers√£o para formato `Parquet` usando `Dask.to_parquet()`
   - Organiza√ß√£o em diret√≥rios por m√™s/ano e tipo de dado

5. **Consolida√ß√£o em Banco Anal√≠tico**
   - Verifica√ß√£o dos arquivos Parquet gerados para cada tipo de dado
   - Jun√ß√£o de todos os arquivos Parquet em um √∫nico banco DuckDB
   - Cria√ß√£o de tabelas, views e otimiza√ß√µes para an√°lise

6. **Finaliza√ß√£o**
   - Encerramento do cliente Dask
   - Gera√ß√£o de logs de conclus√£o

### Ferramentas Utilizadas Atualmente

- **Processamento distribu√≠do:** Dask
- **Download:** PyCurl, requests
- **Parsing HTML:** BeautifulSoup
- **Armazenamento:** Parquet (via Dask)
- **Banco de dados anal√≠tico:** DuckDB

## ‚ú® Caracter√≠sticas

- **Download Paralelo**: Baixa m√∫ltiplos arquivos simultaneamente
- **Sistema de Cache**: Evita baixar novamente arquivos recentemente processados
- **Verifica√ß√£o de Espa√ßo em Disco**: Garante espa√ßo suficiente antes do processamento
- **Verifica√ß√£o de Conex√£o**: Verifica conectividade com a internet antes dos downloads
- **Tratamento Espec√≠fico de Exce√ß√µes**: Melhor robustez e recupera√ß√£o de falhas
- **Paraleliza√ß√£o do Processamento**: Processamento eficiente de arquivos CSV usando Dask e ThreadPoolExecutor
- **Resili√™ncia**: Sistema de retry autom√°tico em caso de falhas
- **Processamento Eficiente**: Utiliza Dask para processamento paralelo
- **Armazenamento Otimizado**: Dados em formato Parquet e DuckDB
- **Logging Detalhado**: Rastreamento completo das opera√ß√µes
- **Configur√°vel**: F√°cil adapta√ß√£o √†s necessidades espec√≠ficas
- **Convers√£o Robusta de Tipos**: Tratamento avan√ßado para campos num√©ricos, datas e valores monet√°rios

## üìù Logs e Monitoramento

- Logs s√£o gerados em `logs/cnpj_process_YYYYMMDD_HHMMSS.log`
- Dashboard Dask dispon√≠vel em `http://localhost:8787`
- Progresso de downloads exibido em tempo real
- Logs detalhados de erros com tratamento espec√≠fico por tipo de exce√ß√£o

## ‚öôÔ∏è Configura√ß√µes

O arquivo `config.py` permite ajustar:

- **Processamento**
  - N√∫mero de workers Dask (`config.dask.n_workers`)
  - Threads por worker
  - Limite de mem√≥ria

- **Cache**
  - Habilitar/desabilitar cache (`config.cache.enabled`)
  - Diret√≥rio do cache (`config.cache.cache_dir`)
  - Tempo de expira√ß√£o do cache (`config.cache.max_age_days`)

- **Arquivos**
  - Encoding
  - Separador
  - Tipos de dados

- **Banco de Dados**
  - N√∫mero de threads
  - Configura√ß√µes de compress√£o

## üìã Sugest√µes de Otimiza√ß√£o

O fluxo de processamento pode ser aprimorado conforme o diagrama e sugest√µes a seguir:

```mermaid
---
config:
   theme: neutral
   layout: elk
   elk:
      direction: DOWN
      nodeSpacing: 70
      rankSpacing: 100
      mergeEdges: false
      spacing: 70
      layeringStrategy: NETWORK_SIMPLEX
      nodePlacementStrategy: BRANDES_KOEPF
      algorithm: layered
      layered:
        alignedLayout: true
        nodePlacement: SIMPLE
   flowchart:
      useMaxWidth: true
      curve: basis
      defaultRenderer: elk
      htmlLabels: true
      animate: true

---
flowchart TD
    %% Etapa 1: Inicializa√ß√£o e Verifica√ß√£o
    A[In√≠cio] --> B[Configura√ß√£o do ambiente]
    B --> C[Inicializa√ß√£o do Dask Cluster]
    C --> D[Verifica√ß√£o de novas vers√µes de dados CNPJ]
    D --> D1{Novos dados CNPJ dispon√≠veis?}
    D1 -->|N√£o| P1[Encerramento do Dask]
    P1 --> Z[Fim]
    
    %% Etapa 2: Prepara√ß√£o com Cache
    D1 -->|Sim| E[Consulta ao cache de metadados]
    E --> E1{√â necess√°rio download completo?}
    E1 -->|Sim| F1[Download paralelo com asyncio]
    E1 -->|N√£o| F2[Download seletivo de arquivos]
    F1 --> G[Descompacta√ß√£o paralela]
    F2 --> G
    G --> H[Atualiza√ß√£o do cache]
    
    %% Etapa 3: Loop de Processamento com Dask otimizado
    H --> T[Loop por tipos de dados]
    T --> I[Processamento e transforma√ß√£o com Dask]
    
    %% Conex√£o direta para valida√ß√£o
    I --> J[Valida√ß√£o de dados avan√ßada]
    J --> J1{Dados OK?}
    J1 -->|N√£o| J2[Corre√ß√£o com transforma√ß√µes Dask]
    J2 --> J
    J1 -->|Sim| K[Armazenamento em Parquet otimizado]
    K --> T1{Mais tipos de dados?}
    T1 -->|Sim| T
    
    %% Etapa 4: Consolida√ß√£o e Finaliza√ß√£o
    T1 -->|N√£o| L[Verifica√ß√£o dos arquivos Parquet]
    L --> L1{Parquets completos?}
    L1 -->|N√£o| P1
    L1 -->|Sim| M[Cria√ß√£o de views otimizadas no DuckDB]
    M --> P1
    
    %% Estilos mais claros
    classDef processo fill:#d1e7dd,stroke:#0d6832,stroke-width:1px
    classDef novo fill:#a3cfbb,stroke:#0d6832,stroke-width:2px
    classDef decisao fill:#fff3cd,stroke:#856404,stroke-width:1px
    classDef inicio fill:#cfe2ff,stroke:#084298,stroke-width:1px
    classDef fim fill:#f8d7da,stroke:#842029,stroke-width:1px
    classDef loop fill:#e0cffc,stroke:#6f42c1,stroke-width:1px
    classDef dask fill:#d5e5f9,stroke:#084298,stroke-width:1px
    
    class A,B inicio
    class D1,J1,T1,L1 decisao
    class F1,F2,G,J2,M novo
    class E,H processo
    class C,I,J,K,L,P1 dask
    class T loop
    class Z fim
    
    %% Anima√ß√£o das setas
    linkStyle default stroke:#00AA00,stroke-width:2px,color:green,animation:flowing 2s ease infinite,stroke-dasharray:5,2,3,2
```

### 1. Paraleliza√ß√£o e Desempenho

#### Downloads Ass√≠ncronos
- Implementar downloads paralelos com `asyncio` e `aiohttp`
- Redu√ß√£o de 60-80% no tempo de download total
- Funciona em conjunto com o cache de metadados

```bash
# Criar branch para implementa√ß√£o de downloads ass√≠ncronos
git checkout -b feature/async-downloads master
```

#### Descompacta√ß√£o em Paralelo
- Usar `concurrent.futures` para extrair m√∫ltiplos arquivos simultaneamente
- Redu√ß√£o significativa no tempo de extra√ß√£o

```bash
# Criar branch para implementa√ß√£o de descompacta√ß√£o paralela
git checkout -b feature/parallel-extraction master
```

#### Cache de Metadados

- Implementar cache de metadados (SQLite ou arquivo JSON)
- Evitar reprocessamento desnecess√°rio, processando apenas o que mudou

```bash
# Criar branch para implementa√ß√£o do cache de metadados
git checkout -b feature/metadata-cache master
```

### 2. Migra√ß√£o Completa para Dask

#### Substitui√ß√£o de Pandas por Dask
- Identificar todas as partes do c√≥digo que usam Pandas diretamente
- Converter opera√ß√µes Pandas para suas equivalentes em Dask
- Garantir que toda a pipeline de dados aproveite o processamento paralelo

```bash
# Criar branch para migra√ß√£o completa para Dask
git checkout -b feature/pandas-to-dask master
```

#### Refatora√ß√£o de C√≥digo para Processamento Lazy
- Implementar padr√µes de processamento lazy/tardio
- Evitar materializa√ß√£o desnecess√°ria de DataFrames
- Otimizar cadeia de transforma√ß√µes

```bash
# Criar branch para refatora√ß√£o para processamento lazy
git checkout -b feature/lazy-processing master
```

### 3. Otimiza√ß√µes do Dask

#### Otimiza√ß√£o do Dask
- Melhorar a configura√ß√£o e utiliza√ß√£o do Dask
- Implementar particionamento otimizado
- Utilizar funcionalidades avan√ßadas como Dask Bag para processamento inicial

```bash
# Criar branch para otimiza√ß√£o do Dask
git checkout -b feature/dask-optimization master
```

#### Formato de Armazenamento Otimizado

- Otimiza√ß√£o avan√ßada do Parquet com compress√£o e estat√≠sticas
- Melhoria de esquemas e particionamento de dados
- Implementa√ß√£o de caching de resultados intermedi√°rios

```bash
# Criar branch para implementa√ß√£o de armazenamento otimizado
git checkout -b feature/optimized-storage master
```

#### Valida√ß√£o de Dados Integrada

- Implementar valida√ß√£o integrada ao fluxo de processamento
- Esquemas de valida√ß√£o para cada tipo de dados
- Corre√ß√£o autom√°tica de problemas comuns

```bash
# Criar branch para implementa√ß√£o de valida√ß√£o de dados integrada
git checkout -b feature/integrated-validation master
```

### 4. Resili√™ncia e Monitoramento

#### Checkpoints de Recupera√ß√£o

- Implementar sistema de checkpoints para recupera√ß√£o de falhas
- Capacidade de retomar de falhas sem reprocessamento completo

```bash
# Criar branch para implementa√ß√£o de checkpoints de recupera√ß√£o
git checkout -b feature/recovery-checkpoints master
```

#### Sistema de Monitoramento

- Melhorar a integra√ß√£o com dashboard Dask
- Adicionar m√©tricas e monitoramento avan√ßado
- Integra√ß√£o com sistemas de observabilidade

```bash
# Criar branch para implementa√ß√£o do sistema de monitoramento
git checkout -b feature/monitoring-system master
```

#### Tratamento Avan√ßado de Erros

- Melhorar o sistema de tratamento de erros
- Logging detalhado com categoriza√ß√£o de problemas
- Estrat√©gias de recupera√ß√£o por tipo de erro

```bash
# Criar branch para implementa√ß√£o de tratamento avan√ßado de erros
git checkout -b feature/advanced-error-handling master
```

### 5. Arquitetura Geral

#### Pipeline Modular

- Arquitetura em etapas independentes
- Facilidade de manuten√ß√£o e possibilidade de executar apenas partes espec√≠ficas

```bash
# Criar branch para implementa√ß√£o de pipeline modular
git checkout -b feature/modular-pipeline master
```

#### Integra√ß√£o Avan√ßada com DuckDB

- Melhorar a integra√ß√£o entre Dask e DuckDB
- Otimiza√ß√£o de querys e carregamento
- Cria√ß√£o de visualiza√ß√µes anal√≠ticas

```bash
# Criar branch para implementa√ß√£o de integra√ß√£o com DuckDB
git checkout -b feature/duckdb-integration master
```

## üìä Compara√ß√£o de Tecnologias Atuais e Otimizadas

| Aspecto | Atual | Sugest√£o de Otimiza√ß√£o | Benef√≠cio |
|---------|-------|----------|-----------|
| Processamento Distribu√≠do | Dask b√°sico com Pandas em algumas partes | Dask completo com particionamento adequado | Maior velocidade de processamento e uso eficiente de recursos |
| Formato de Armazenamento | Parquet b√°sico via Dask | Parquet otimizado com estat√≠sticas e compress√£o | Melhor compress√£o e desempenho de leitura |
| Download de Arquivos | PyCurl sequencial | asyncio/aiohttp paralelo | Redu√ß√£o de 60-80% no tempo de download |
| Descompacta√ß√£o | zipfile sequencial | concurrent.futures paralelo | Redu√ß√£o significativa no tempo de extra√ß√£o |
| Valida√ß√£o de Dados | M√≠nima | Sistema integrado de valida√ß√£o | Maior qualidade dos dados e robustez |
| Recupera√ß√£o de Falhas | Inexistente | Sistema de checkpoints para retomada | Continuidade em caso de interrup√ß√µes |
| Monitoramento | Logs b√°sicos | Dashboard Dask aprimorado + m√©tricas | Melhor observabilidade |

## üìÖ Plano de Implementa√ß√£o Progressiva

Para implementar estas melhorias de forma gradual e segura:

### Fase 1: Otimiza√ß√µes Imediatas (1-2 semanas)

- Implementar downloads paralelos com asyncio
- Adicionar descompacta√ß√£o em paralelo
- Implementar cache b√°sico de metadados

### Fase 2: Migra√ß√£o Completa para Dask (2-3 semanas)

- Identificar e substituir opera√ß√µes Pandas por Dask
- Refatorar c√≥digo para processamento lazy
- Implementar padr√µes de processamento distribu√≠do em toda a pipeline

### Fase 3: Otimiza√ß√£o do Dask (2-3 semanas)

- Configurar particionamento otimizado do Dask
- Melhorar utiliza√ß√£o de recursos
- Implementar valida√ß√£o de dados integrada

### Fase 4: Otimiza√ß√£o de Fluxo (2-3 semanas)

- Implementar sistema de corre√ß√£o de dados
- Adicionar sistema de checkpoints
- Otimizar armazenamento Parquet

### Fase 5: Refinamentos Finais (1-2 semanas)

- Implementar integra√ß√£o avan√ßada com DuckDB
- Configurar monitoramento e m√©tricas
- Testes de desempenho e ajustes finais


### Tabela de Implementa√ß√£o das Branches

| Fase | Nome da Branch              | Descri√ß√£o                               | Data In√≠cio | Data Previs√£o | Data Conclus√£o | Status | Depend√™ncias |
| :--- | :-------------------------- | :-------------------------------------- | :---------- | :------------ | :------------- | :----- | :--------- |
| 1    | feature/async-downloads     | Implementa√ß√£o de downloads ass√≠ncronos  | 10/04/2025  | 15/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 1    | feature/parallel-extraction | Descompacta√ß√£o em paralelo de arquivos  | 09/04/2025  | 14/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 1    | feature/metadata-cache      | Sistema de cache de metadados           | 15/04/2025  | 24/04/2025    | 08/04/2025     | ‚úÖ     | -            |
| 2    | feature/pandas-to-dask      | Migra√ß√£o de opera√ß√µes Pandas para Dask  | 25/04/2025  | 05/05/2025    | -              | ‚è≥     | -            |
| 2    | feature/lazy-processing     | Refatora√ß√£o para processamento lazy     | 06/05/2025  | 15/05/2025    | -              | ‚è≥     | feature/pandas-to-dask |
| 3    | feature/dask-optimization   | Otimiza√ß√£o do Dask e particionamento    | 16/05/2025  | 25/05/2025    | -              | ‚è≥     | feature/lazy-processing |
| 3    | feature/optimized-storage   | Otimiza√ß√£o do formato de armazenamento  | 26/05/2025  | 02/06/2025    | -              | ‚è≥     | feature/dask-optimization |
| 3    | feature/integrated-validation | Valida√ß√£o integrada de dados  | 03/06/2025  | 10/06/2025    | -              | ‚è≥     | feature/dask-optimization |
| 4    | feature/recovery-checkpoints| Sistema de checkpoints para recupera√ß√£o | 11/06/2025  | 18/06/2025    | -              | ‚è≥     | feature/integrated-validation |
| 4    | feature/advanced-error-handling| Tratamento avan√ßado de erros         | 11/06/2025  | 18/06/2025    | -              | ‚è≥     | feature/integrated-validation |
| 4    | feature/monitoring-system   | Implementa√ß√£o de sistema de monitoramento| 19/06/2025  | 26/06/2025    | -              | ‚è≥     | feature/recovery-checkpoints |
| 5    | feature/modular-pipeline    | Implementa√ß√£o de pipeline modular       | 27/06/2025  | 04/07/2025    | -              | ‚è≥     | feature/monitoring-system |
| 5    | feature/duckdb-integration  | Integra√ß√£o avan√ßada com DuckDB          | 27/06/2025  | 04/07/2025    | -              | ‚è≥     | feature/monitoring-system |

### Diagrama de Gantt do Plano de Implementa√ß√£o

O diagrama abaixo ilustra a programa√ß√£o temporal das tarefas, suas interdepend√™ncias e o caminho cr√≠tico do projeto de otimiza√ß√£o:

```mermaid
gantt
    title Cronograma de Implementa√ß√£o das Otimiza√ß√µes do Fluxo CNPJ
    dateFormat  YYYY-MM-DD
    axisFormat %d/%m
    excludes weekends 2025-04-17 2025-04-18 2025-04-21 2025-05-01 2025-05-02 2025-06-19 2025-06-20
    
    %% Feriados brasileiros e pontos facultativos
    section Dias N√£o √öteis
    Ponto Facultativo (antes da Paix√£o)       :crit, active, holiday0a, 2025-04-17, 1d
    Sexta-feira da Paix√£o                    :crit, active, holiday0, 2025-04-18, 1d
    Tiradentes                               :crit, active, holiday1, 2025-04-21, 1d
    Dia do Trabalho                          :crit, active, holiday2, 2025-05-01, 1d
    Ponto Facultativo (ap√≥s Dia do Trabalho) :crit, active, holiday2b, 2025-05-02, 1d
    Corpus Christi                           :crit, active, holiday3, 2025-06-19, 1d
    Ponto Facultativo (ap√≥s Corpus Christi)  :crit, active, holiday3b, 2025-06-20, 1d
    
    section Fase 1: Otimiza√ß√µes Imediatas
    An√°lise inicial e planejamento detalhado    :a1, 2025-04-14, 3d
    Implementar downloads paralelos com asyncio  :a2, after a1, 4d
    Adicionar descompacta√ß√£o em paralelo        :a3, after a1, 4d
    Implementar cache b√°sico de metadados       :a4, after a2 a3, 5d
    Testes de performance da Fase 1             :a5, after a4, 2d
    
    section Fase 2: Migra√ß√£o Completa para Dask
    Identificar e substituir opera√ß√µes Pandas    :b1, after a5, 7d
    Refatorar para processamento lazy            :b2, after b1, 6d
    Testes de compatibilidade                    :b3, after b2, 3d
    
    section Fase 3: Otimiza√ß√£o do Dask
    Configurar particionamento otimizado        :c1, after b3, 5d
    Melhorar utiliza√ß√£o de recursos             :c2, after c1, 3d
    Implementar valida√ß√£o de dados integrada    :c3, after c2, 5d
    Testes de otimiza√ß√£o do Dask                :c4, after c3, 3d
    
    section Fase 4: Otimiza√ß√£o de Fluxo
    Implementar sistema de corre√ß√£o de dados    :d1, after c4, 5d
    Adicionar sistema de checkpoints            :d2, after d1, 4d
    Otimizar armazenamento Parquet              :d3, after d1, 5d
    Testes de carga do fluxo completo           :d4, after d2 d3, 3d
    
    section Fase 5: Refinamentos Finais
    Implementar integra√ß√£o avan√ßada com DuckDB  :e1, after d4, 4d
    Configurar monitoramento e m√©tricas         :e2, after d4, 4d
    Testes finais de desempenho                 :e3, after e1 e2, 3d
    Documenta√ß√£o e treinamento                  :e4, after e3, 2d
```

O diagrama acima representa:

- **Dura√ß√£o das tarefas**: Cada barra representa uma tarefa com sua dura√ß√£o estimada
- **Depend√™ncias**: As tarefas conectadas mostram quais precisam ser conclu√≠das antes de outras come√ßarem
- **Agrupamento**: As tarefas est√£o organizadas nas cinco fases do plano de implementa√ß√£o
- **Caminho cr√≠tico**: A sequ√™ncia de tarefas que determina a dura√ß√£o total do projeto

Este cronograma prev√™ aproximadamente 12-14 semanas para a implementa√ß√£o completa, considerando as depend√™ncias entre tarefas e tempos realistas para desenvolvimento e testes.

## Otimiza√ß√µes de Processamento

Este projeto foi otimizado para lidar com grandes volumes de dados de maneira eficiente. 
As seguintes otimiza√ß√µes foram implementadas:

### Processamento sequencial de arquivos ZIP

Em vez de descompactar todos os arquivos de uma vez (o que poderia consumir muito espa√ßo em disco), 
o processamento agora √© feito sequencialmente:

1. Cada arquivo ZIP √© descompactado individualmente
2. Os arquivos CSV resultantes s√£o processados em paralelo
3. Os arquivos tempor√°rios s√£o exclu√≠dos imediatamente
4. S√≥ ent√£o o pr√≥ximo arquivo ZIP √© processado

Essa abordagem tem as seguintes vantagens:
- Reduz significativamente o uso de espa√ßo em disco
- Previne vazamentos de mem√≥ria durante o processamento
- Mant√©m o diret√≥rio de trabalho limpo
- Permite processamento de conjuntos de dados maiores sem esgotar o armazenamento

### Sistema de Cache para Downloads

- Evita baixar novamente arquivos j√° processados recentemente
- Configur√°vel via par√¢metros de tempo de expira√ß√£o
- Fornece comandos para gerenciar o cache (visualizar informa√ß√µes e limpar)

### Paraleliza√ß√£o do Processamento de CSV

- Os arquivos CSV dentro de cada ZIP s√£o processados em paralelo
- Utiliza ThreadPoolExecutor e Dask para processamento eficiente
- N√∫mero de workers configur√°vel via `config.dask.n_workers`

### Tratamento Espec√≠fico de Exce√ß√µes

- Implementado tratamento espec√≠fico para diferentes tipos de exce√ß√µes
- Mensagens de erro detalhadas para facilitar a depura√ß√£o
- Melhor robustez e recupera√ß√£o de falhas

### Verifica√ß√µes de Seguran√ßa

- Verifica√ß√£o de espa√ßo em disco antes de iniciar o processamento
- Verifica√ß√£o de espa√ßo antes de descompactar cada arquivo ZIP
- Verifica√ß√£o de conex√£o com a internet antes de iniciar downloads
- Estimativa do tamanho de arquivos ap√≥s descompacta√ß√£o

### Limpeza de arquivos tempor√°rios

Todos os arquivos tempor√°rios descompactados s√£o exclu√≠dos ap√≥s o processamento, mesmo em caso de erro,
garantindo que n√£o fiquem arquivos residuais no sistema.

### Melhorias na Convers√£o de Tipos

- **Tratamento robusto para valores num√©ricos**: Convers√£o segura para Int64 com suporte para valores nulos
- **Convers√£o avan√ßada de datas**: Tratamento melhorado para valores inv√°lidos (zeros, valores vazios, etc.)
- **Processamento de valores monet√°rios**: Convers√£o adequada de valores com v√≠rgulas como separador decimal
- **Valida√ß√£o de tipos ap√≥s convers√£o**: Verifica√ß√£o da integridade dos dados p√≥s-convers√£o
- **Logs detalhados**: Rastreamento do processo de convers√£o para facilitar depura√ß√£o

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ‚ö†Ô∏è Notas

- O processamento pode levar algumas horas dependendo do hardware
- Requisitos m√≠nimos de espa√ßo em disco:
  - Empresas: 5GB
  - Estabelecimentos: 8GB
  - Simples Nacional: 3GB
- Em caso de falhas, o sistema tentar√° novamente automaticamente
- Verifica√ß√£o de espa√ßo em disco √© realizada antes da descompacta√ß√£o

## üõ†Ô∏è Processamento e Regras de Neg√≥cio

Durante o processamento, v√°rias transforma√ß√µes e regras de neg√≥cio s√£o aplicadas, especialmente aos dados de Empresas:

1.  **Convers√£o de Tipos**: Colunas num√©ricas e de data s√£o convertidas para os tipos apropriados.
2.  **Renomea√ß√£o**: Algumas colunas s√£o renomeadas para maior clareza (ex: `razao_social_nome_empresarial` para `razao_social`).
3.  **Extra√ß√£o de CPF**: 
    - O CPF (Pessoa F√≠sica) √© extra√≠do da coluna `razao_social`.
    - O script busca por padr√µes formatados (`xxx.xxx.xxx-xx`) ou por sequ√™ncias de 11 d√≠gitos.
    - O CPF extra√≠do (apenas os 11 d√≠gitos) √© armazenado em uma nova coluna chamada `CPF`.
    - Esta coluna n√£o √© obrigat√≥ria, pois nem todas as raz√µes sociais conter√£o um CPF.
4.  **Limpeza da Raz√£o Social**: Ap√≥s a extra√ß√£o do CPF, o mesmo √© **removido** da coluna `razao_social` original para manter apenas o nome/raz√£o social. Espa√ßos extras s√£o removidos.

Essas transforma√ß√µes s√£o implementadas nas fun√ß√µes `apply_empresa_transformations_pandas`, `apply_empresa_transformations_polars`, e `apply_empresa_transformations_dask` dentro de `src/process/empresa.py`.

## ‚ú® Caracter√≠sticas

- **Automatizado**: Busca, baixa e processa os dados automaticamente.
- **Resiliente**: Possui retries em caso de falha no download e verifica√ß√µes de integridade.

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.

## üìú Licen√ßa

Este projeto est√° licenciado sob a [MIT License](LICENSE).

## üìù Notas

- Os dados da Receita Federal s√£o atualizados periodicamente. Execute o script regularmente para manter seus dados atualizados.
- O processamento pode exigir uma quantidade significativa de recursos (CPU, mem√≥ria, disco) dependendo do volume de dados.

---
*Desenvolvido com ‚ù§Ô∏è e Python!* 

