# Processador de Dados CNPJ üè¢

Este projeto automatiza o download, processamento e armazenamento dos dados p√∫blicos de CNPJ disponibilizados pela Receita Federal. Ele foi desenvolvido para ser eficiente, resiliente e f√°cil de usar.

## üìã Fluxo do Processo

```mermaid
graph TD
    A[In√≠cio] --> B[Configura√ß√£o do Ambiente]
    B --> C[Inicializa√ß√£o do Dask]
    
    C --> D[Identifica√ß√£o de Arquivos]
    D --> E[Download Paralelo]
    
    E --> F{Verifica√ß√£o de Falhas}
    F -->|Falha| G[Retry Autom√°tico]
    G --> E
    F -->|Sucesso| H[Extra√ß√£o de ZIPs]
    
    H --> I[Processamento com Dask]
    I --> J[Gera√ß√£o de Parquet]
    
    J --> K[Cria√ß√£o do DuckDB]
    K --> L[C√≥pia para Remoto]
    L --> M[Fim]

    subgraph "Download e Verifica√ß√£o"
        E
        F
        G
    end

    subgraph "Processamento"
        H
        I
        J
    end

    subgraph "Armazenamento"
        K
        L
    end

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style M fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#ff9,stroke:#333,stroke-width:2px
```

## ‚ú® Caracter√≠sticas

- **Download Paralelo**: Baixa m√∫ltiplos arquivos simultaneamente
- **Resili√™ncia**: Sistema de retry autom√°tico em caso de falhas
- **Processamento Eficiente**: Utiliza Dask para processamento paralelo
- **Armazenamento Otimizado**: Dados em formato Parquet e DuckDB
- **Logging Detalhado**: Rastreamento completo das opera√ß√µes
- **Configur√°vel**: F√°cil adapta√ß√£o √†s necessidades espec√≠ficas

## üöÄ Como Usar

### Pr√©-requisitos

- Python 3.8 ou superior
- Espa√ßo em disco suficiente para os arquivos
- Conex√£o com internet est√°vel

### Instala√ß√£o

1. **Clone o reposit√≥rio**
```bash
git clone https://github.com/seu-usuario/cnpj.git
cd cnpj
```

2. **Crie um ambiente virtual**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

3. **Instale as depend√™ncias**
```bash
pip install -r requirements.txt
```

4. **Configure o ambiente**
   - Copie o arquivo `.env.local.example` para `.env.local`
   - Ajuste as configura√ß√µes conforme necess√°rio:
```env
# URL base dos dados da Receita Federal
URL_ORIGIN=https://dados.rfb.gov.br/CNPJ/

# Diret√≥rios para download e processamento
PATH_ZIP=./download/      # Arquivos ZIP baixados
PATH_UNZIP=./unzip/      # Arquivos extra√≠dos
PATH_PARQUET=./parquet/  # Arquivos Parquet processados

# Configura√ß√µes do banco de dados
FILE_DB_PARQUET=cnpj.duckdb
PATH_REMOTE_PARQUET=//servidor/compartilhado/
```

### Execu√ß√£o

```bash
python main.py
```

## üìä O que o Script Faz

1. **Download dos Dados**
   - Identifica os arquivos mais recentes
   - Baixa em paralelo com retry autom√°tico
   - Verifica integridade dos arquivos

2. **Processamento**
   - Extrai arquivos ZIP
   - Processa dados com Dask
   - Gera arquivos Parquet otimizados

3. **Armazenamento**
   - Cria banco de dados DuckDB
   - Organiza dados em tabelas
   - Copia para local remoto

## üìù Logs e Monitoramento

- Logs s√£o gerados em `logs/cnpj_process_YYYYMMDD_HHMMSS.log`
- Dashboard Dask dispon√≠vel em `http://localhost:8787`
- Progresso de downloads exibido em tempo real

## ‚öôÔ∏è Configura√ß√µes

O arquivo `config.py` permite ajustar:

- **Processamento**
  - N√∫mero de workers Dask
  - Threads por worker
  - Limite de mem√≥ria

- **Arquivos**
  - Encoding
  - Separador
  - Tipos de dados

- **Banco de Dados**
  - N√∫mero de threads
  - Configura√ß√µes de compress√£o

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Por favor:

1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature
3. Fa√ßa commit das mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ‚ö†Ô∏è Notas

- O processamento pode levar algumas horas dependendo do hardware
- Certifique-se de ter espa√ßo suficiente em disco
- Em caso de falhas, o sistema tentar√° novamente automaticamente

## Otimiza√ß√µes de Processamento

Este projeto foi otimizado para lidar com grandes volumes de dados de maneira eficiente. 
As seguintes otimiza√ß√µes foram implementadas:

### Processamento sequencial de arquivos ZIP

Em vez de descompactar todos os arquivos de uma vez (o que poderia consumir muito espa√ßo em disco), 
o processamento agora √© feito sequencialmente:

1. Cada arquivo ZIP √© descompactado individualmente
2. Os arquivos CSV resultantes s√£o processados
3. Os arquivos tempor√°rios s√£o exclu√≠dos imediatamente
4. S√≥ ent√£o o pr√≥ximo arquivo ZIP √© processado

Essa abordagem tem as seguintes vantagens:
- Reduz significativamente o uso de espa√ßo em disco
- Previne vazamentos de mem√≥ria durante o processamento
- Mant√©m o diret√≥rio de trabalho limpo
- Permite processamento de conjuntos de dados maiores sem esgotar o armazenamento

### Limpeza de arquivos tempor√°rios

Todos os arquivos tempor√°rios descompactados s√£o exclu√≠dos ap√≥s o processamento, mesmo em caso de erro,
garantindo que n√£o fiquem arquivos residuais no sistema. A exclus√£o √© feita usando processamento paralelo
para maior efici√™ncia.
