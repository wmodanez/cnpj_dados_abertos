# Processador de Painel - Sistema Completo

## Vis√£o Geral

O **PainelProcessor** √© um sistema completo para processamento de dados da Receita Federal que combina informa√ß√µes de **Estabelecimentos**, **Simples Nacional** e **Empresas** em um painel consolidado.

### Caracter√≠sticas Principais

‚úÖ **Pipeline Completo**: Download ‚Üí Descompacta√ß√£o ‚Üí Processamento ‚Üí Painel  
‚úÖ **Processamento Flex√≠vel**: Detecta automaticamente o estado dos dados  
‚úÖ **Joins Otimizados**: LEFT JOIN (Estabelecimento + Simples) + INNER JOIN (Empresa)  
‚úÖ **CNPJ Bigint**: Utiliza `pl.Int64` para m√°xima performance em joins  
‚úÖ **Filtros Inteligentes**: Por UF, situa√ß√£o cadastral, etc.  
‚úÖ **Relat√≥rios Autom√°ticos**: Estat√≠sticas detalhadas dos dados processados  

---

## üöÄ Uso via main.py (NOVO)

Agora voc√™ pode processar o painel diretamente atrav√©s do `main.py` usando os novos argumentos:

### Argumentos Dispon√≠veis
- `--processar-painel` (`-P`): Ativa o processamento do painel
- `--painel-uf UF`: Filtra por UF espec√≠fica (ex: SP, GO)
- `--painel-situacao CODIGO`: Filtra por situa√ß√£o cadastral (1=Nula, 2=Ativa, 3=Suspensa, 4=Inapta, 8=Baixada)
- `--painel-incluir-inativos`: Inclui estabelecimentos inativos no painel

### Exemplos Pr√°ticos via Linha de Comando

#### 1. Processamento Completo com Painel (TODOS OS DADOS - SEM FILTROS)
```bash
python main.py --processar-painel
```
**Este √© o comando mais b√°sico** - processa todos os estabelecimentos, empresas e simples nacional do Brasil inteiro, incluindo apenas estabelecimentos ativos.

#### 2. Processamento Completo com TODOS OS DADOS (Incluindo Inativos)
```bash
python main.py --processar-painel --painel-incluir-inativos
```
**Vers√£o mais completa** - inclui todos os estabelecimentos (ativos E inativos) do Brasil inteiro.

#### 3. Painel Filtrado por S√£o Paulo (Apenas Ativos)
```bash
python main.py --processar-painel --painel-uf SP --painel-situacao 2
```

#### 4. Painel para Goi√°s incluindo inativos
```bash
python main.py --processar-painel --painel-uf GO --painel-incluir-inativos
```

#### 5. Processamento com Tipos Espec√≠ficos + Painel
```bash
python main.py --tipos empresas estabelecimentos simples --processar-painel --painel-uf MG
```

#### 6. Painel de Pasta Remota Espec√≠fica
```bash
python main.py --remote-folder 2024-01 --processar-painel --painel-situacao 2
```

#### 7. Pipeline Completo com Economia M√°xima (TODOS OS DADOS)
```bash
python main.py --processar-painel --cleanup-all-after-db
```
**Recomendado para produ√ß√£o** - processa todos os dados e limpa arquivos intermedi√°rios para economizar espa√ßo.

#### 8. Processamento Silencioso para Automa√ß√£o (TODOS OS DADOS)
```bash
python main.py --processar-painel --quiet
```
**Ideal para scripts automatizados** - processa todos os dados sem interface visual.

---

## ‚ö° Processamento Paralelo

**SIM, o processamento est√° sendo feito em paralelo!** O sistema implementa v√°rias camadas de paraleliza√ß√£o:

### üîÑ Paraleliza√ß√£o no Pipeline Principal

#### 1. Downloads Simult√¢neos
- **At√© 6 downloads simult√¢neos** por padr√£o (adaptativo baseado na rede)
- **Configura√ß√£o autom√°tica** baseada na qualidade da conex√£o
- **Sem√°foros adaptativos** para controle de recursos

```python
# Download autom√°tico com workers adaptativos
max_concurrent_downloads = network_results["recommendations"]["max_concurrent_downloads"]
download_semaphore = asyncio.Semaphore(max_concurrent_downloads)
```

#### 2. Processamento Ass√≠ncrono
- **Pipeline imediato**: arquivos s√£o processados assim que baixados
- **Workers m√∫ltiplos** para processamento paralelo
- **Fila de processamento** para otimizar uso de recursos

```python
# Workers de processamento autom√°ticos baseados em CPU/RAM
max_concurrent_processing = min(cpu_count, max(min_workers, cpu_count * 3 // 4))
```

#### 3. Joins Otimizados com Polars
- **Lazy Loading**: carregamento otimizado dos dados
- **Joins paralelos**: LEFT JOIN + INNER JOIN executados de forma otimizada
- **CNPJ Bigint**: performance 3-5x melhor que strings

### üß† Detec√ß√£o Autom√°tica de Recursos

O sistema detecta automaticamente:
- **N√∫mero de CPUs** dispon√≠veis
- **Quantidade de RAM** dispon√≠vel  
- **Qualidade da conex√£o** de rede
- **Espa√ßo em disco** dispon√≠vel

```python
# Configura√ß√£o autom√°tica baseada no hardware
if memory_gb >= 16:
    max_workers = cpu_count * 3 // 4  # 75% dos cores
elif memory_gb >= 8:
    max_workers = cpu_count * 2 // 3  # 66% dos cores
else:
    max_workers = cpu_count // 2      # 50% dos cores
```

### üìä Processamento Individual Paralelo

Cada tipo de dados √© processado em paralelo:

```python
# Processamento simult√¢neo de m√∫ltiplos tipos
tipos_processados_em_paralelo = [
    'empresas',         # Worker 1
    'estabelecimentos', # Worker 2  
    'simples',         # Worker 3
    'socios'          # Worker 4
]
```

### üîß Paraleliza√ß√£o do Painel

O processamento do painel **N√ÉO √© paralelo internamente** (os JOINs s√£o sequenciais), mas:

‚úÖ **Carregamento paralelo** dos parquets de entrada  
‚úÖ **Joins otimizados** com Polars (usa m√∫ltiplos threads internamente)  
‚úÖ **Escrita paralela** do parquet final  

### üìà Performance Esperada

Com paraleliza√ß√£o ativa:
- **Download**: 3-6x mais r√°pido que sequencial
- **Processamento**: 2-4x mais r√°pido que sequencial  
- **Pipeline completo**: 50-70% de redu√ß√£o no tempo total

### ‚öôÔ∏è Controle Manual

Voc√™ pode controlar a paraleliza√ß√£o via configura√ß√£o:

```python
config.n_workers = 8  # For√ßar n√∫mero espec√≠fico de workers
config.pipeline.max_concurrent_downloads = 4  # Limitar downloads
```

---

## Pipeline de Dados

```mermaid
graph LR
    A[Download ZIPs] --> B[Descompactar]
    B --> C[Processar Estabelecimentos]
    B --> D[Processar Simples Nacional]
    B --> E[Processar Empresas]
    C --> F[LEFT JOIN Est + Simples]
    D --> F
    F --> G[INNER JOIN + Empresa]
    E --> G
    G --> H[Aplicar Filtros]
    H --> I[Painel Final]
```

### Relacionamentos entre Entidades

```sql
-- Pipeline de JOINs do Painel
SELECT *
FROM estabelecimentos e
LEFT JOIN simples_nacional s ON e.cnpj_basico = s.cnpj_basico
INNER JOIN empresas emp ON e.cnpj_basico = emp.cnpj_basico
WHERE e.uf != 'EX'  -- Excluir exterior
```

---

## Modos de Uso

### 0. üöÄ Processamento de TODOS OS DADOS (Modo Mais Simples)

```python
# Via linha de comando (RECOMENDADO)
python main.py --processar-painel

# Ou via c√≥digo Python
from src.process.processors.painel_processor import PainelProcessor

processor = PainelProcessor(
    path_zip='/dados/zips',
    path_unzip='/dados/temp',
    path_parquet='/dados/output'
    # Sem filtros = todos os dados
)

sucesso = processor.process_complete_painel()
```

### 1. üöÄ Processamento Completo (Desde Download)

```python
from src.process.processors.painel_processor import PainelProcessor

# Configura√ß√£o para processamento completo
config = {
    'path_zip': '/dados/zips',
    'path_unzip': '/dados/temp', 
    'path_parquet': '/dados/output',
    
    # Filtros (opcionais)
    'uf_filter': 'SP',        # Apenas S√£o Paulo
    'situacao_filter': 2,     # Apenas ativos
    'include_inactive': False, # Excluir inativos
    
    # Controle do pipeline
    'force_reprocess': False,
    'skip_download': False,
    'skip_unzip': False,
    'skip_individual_processing': False
}

processor = PainelProcessor(**config)
sucesso = processor.process_complete_painel(
    output_filename='painel_sp_ativos.parquet'
)
```

### 2. üìÅ Usando Parquets J√° Processados

```python
# Quando voc√™ j√° tem os parquets das entidades individuais
config = {
    'path_parquet': '/dados/output',
    
    # Caminhos espec√≠ficos
    'estabelecimento_path': '/dados/estabelecimentos.parquet',
    'simples_path': '/dados/simples.parquet', 
    'empresa_path': '/dados/empresas.parquet',
    
    # Pular etapas desnecess√°rias
    'skip_download': True,
    'skip_unzip': True,
    'skip_individual_processing': True,
    
    # Filtros
    'uf_filter': 'GO'
}

processor = PainelProcessor(**config)
try:
    sucesso = processor.process_painel_data('painel_go.parquet')
```

### 3. üîÑ Modo Autom√°tico (Detec√ß√£o Inteligente)

```python
# O processador decide automaticamente o que fazer
config = {
    'path_zip': '/dados/zips',
    'path_unzip': '/dados/temp',
    'path_parquet': '/dados/output'
}

processor = PainelProcessor(**config)

# O sistema ir√°:
# 1. Verificar se existem parquets ‚Üí usar se dispon√≠veis
# 2. Se n√£o, verificar CSVs ‚Üí processar se dispon√≠veis  
# 3. Se n√£o, verificar ZIPs ‚Üí descompactar e processar
# 4. Se n√£o, fazer download ‚Üí pipeline completo

sucesso = processor.process_complete_painel()
```

---

## Par√¢metros de Configura√ß√£o

### üìÇ Caminhos Essenciais
```python
{
    'path_zip': str,          # Diret√≥rio com arquivos ZIP
    'path_unzip': str,        # Diret√≥rio para extra√ß√£o
    'path_parquet': str,      # Diret√≥rio de sa√≠da
}
```

### üìÑ Caminhos Espec√≠ficos (Opcionais)
```python
{
    'estabelecimento_path': str,  # Caminho para parquets de estabelecimentos
    'simples_path': str,          # Caminho para parquets do Simples Nacional
    'empresa_path': str,          # Caminho para parquets de empresas
}
```

### üéõÔ∏è Controle do Pipeline
```python
{
    'force_reprocess': bool,              # For√ßar reprocessamento
    'skip_download': bool,                # Pular download
    'skip_unzip': bool,                   # Pular descompacta√ß√£o
    'skip_individual_processing': bool,   # Pular processamento individual
}
```

### üîç Filtros e Op√ß√µes
```python
{
    'uf_filter': str,           # Filtrar por UF espec√≠fica
    'situacao_filter': int,     # Filtrar por situa√ß√£o cadastral
    'include_inactive': bool,   # Incluir estabelecimentos inativos
}
```

---

## Estrutura do Painel Final

### Campos da Entidade Painel

#### üè¢ Dados do Estabelecimento (base)
- `cnpj_basico` (bigint) - CNPJ b√°sico de 8 d√≠gitos
- `matriz_filial` (int) - 1=Matriz, 2=Filial
- `codigo_situacao` (int) - C√≥digo da situa√ß√£o cadastral
- `data_situacao_cadastral` (datetime)
- `codigo_motivo` (int) - Motivo da situa√ß√£o
- `data_inicio_atividades` (datetime)
- `codigo_cnae` (int) - CNAE principal
- `uf` (string) - Unidade Federativa
- `codigo_municipio` (int)
- `tipo_situacao_cadastral` (int)

#### üè≠ Dados da Empresa (inner join)
- `natureza_juridica` (int) - C√≥digo da natureza jur√≠dica
- `porte_empresa` (int) - 1=Micro, 2=Pequena, 3=M√©dia, 4=Grande, 5=Demais

#### üìä Dados do Simples Nacional (left join)
- `opcao_simples` (string) - S/N
- `data_opcao_simples` (datetime)
- `data_exclusao_simples` (datetime)
- `opcao_mei` (string) - S/N
- `data_opcao_mei` (datetime)
- `data_exclusao_mei` (datetime)

---

## Relat√≥rios e An√°lises

### üìà Relat√≥rio Autom√°tico
O processador gera automaticamente:
- Total de registros processados
- Distribui√ß√£o por UF (Top 10)
- Estat√≠sticas de op√ß√£o pelo Simples Nacional
- Estat√≠sticas de op√ß√£o pelo MEI
- Distribui√ß√£o por tipo (Matriz/Filial)
- Distribui√ß√£o por situa√ß√£o cadastral
- Distribui√ß√£o por porte da empresa

### üîç An√°lise Manual
```python
from src.process.processors.painel_processor import analisar_painel

# Analisar dados do painel gerado
analisar_painel('/dados/output/painel_dados.parquet')
```

---

## Exemplos Pr√°ticos

### Cen√°rio 1: Empresa Nova (Sem Dados)
```python
# Pipeline completo desde download
processor = PainelProcessor(
    path_zip='/dados/downloads',
    path_unzip='/dados/temp',
    path_parquet='/dados/final',
    force_reprocess=True
)

sucesso = processor.process_complete_painel()
```

### Cen√°rio 2: Dados Parciais (Tem ZIPs)
```python
# J√° tem ZIPs, pular download
processor = PainelProcessor(
    path_zip='/dados/zips_existentes',
    path_unzip='/dados/temp',
    path_parquet='/dados/final',
    skip_download=True
)

sucesso = processor.process_complete_painel()
```

### Cen√°rio 3: An√°lise Espec√≠fica (SP, Apenas Ativos)
```python
# Filtro espec√≠fico para S√£o Paulo, apenas estabelecimentos ativos
processor = PainelProcessor(
    path_zip='/dados/zips',
    path_unzip='/dados/temp',
    path_parquet='/dados/sp_ativos',
    uf_filter='SP',
    situacao_filter=2,
    include_inactive=False
)

sucesso = processor.process_complete_painel(
    output_filename='painel_sp_estabelecimentos_ativos.parquet'
)
```

### Cen√°rio 4: Produ√ß√£o (Parquets Existentes)
```python
# Ambiente de produ√ß√£o com dados j√° processados
processor = PainelProcessor(
    path_parquet='/dados/output',
    estabelecimento_path='/dados/prod/estabelecimentos/',
    simples_path='/dados/prod/simples/',
    empresa_path='/dados/prod/empresas/',
    skip_download=True,
    skip_unzip=True,
    skip_individual_processing=True
)

sucesso = processor.process_painel_data('painel_producao.parquet')
```

---

## Performance e Otimiza√ß√µes

### üöÄ Melhorias Implementadas
- **CNPJ Bigint**: Joins 3-5x mais r√°pidos que strings
- **Lazy Loading**: Carregamento otimizado com Polars
- **Compress√£o Snappy**: Arquivos parquet compactados
- **Detec√ß√£o Inteligente**: Evita reprocessamento desnecess√°rio

### üíæ Estimativas de Recursos
- **RAM**: ~8-16GB para dados completos do Brasil
- **Disco**: ~50-100GB para todos os parquets intermedi√°rios
- **Tempo**: ~30-60 minutos pipeline completo (dados 2024)

### ‚ö° Dicas de Performance
1. Use SSD para melhor I/O
2. Configure `skip_*` adequadamente
3. Use filtros para reduzir volume
4. Monitore uso de RAM durante processamento

---

## Tratamento de Erros

### üõ°Ô∏è Valida√ß√µes Autom√°ticas
- Verifica√ß√£o de integridade dos dados
- Valida√ß√£o de relacionamentos entre entidades  
- Detec√ß√£o de inconsist√™ncias em datas
- Exclus√£o autom√°tica de estabelecimentos no exterior (UF=EX)

### üìù Logs Detalhados
```
INFO: Estado atual dos dados: {'precisa_download': False, 'tem_parquets': True}
INFO: Parquets j√° existem, usando dados processados
INFO: Estabelecimentos carregados: 45,123,456 registros
INFO: LEFT JOIN executado. Registros resultantes: 45,123,456
INFO: INNER JOIN executado. Registros finais: 44,987,234
INFO: ‚úì Dados do Painel salvos: /dados/output/painel_dados_20241201_143022.parquet
```

---

## Troubleshooting

### ‚ùå Problemas Comuns

**1. "Parquets de empresas n√£o encontrados"**
```bash
# Verificar se o caminho existe e tem arquivos .parquet
ls -la /caminho/para/empresas/
```

**2. "Falha no processamento individual"**
```python
# Verificar se os processadores individuais existem
from src.process.processors.empresa_processor import EmpresaProcessor
```

**3. "CNPJ b√°sico deve ser um n√∫mero inteiro"**
```python
# Os dados s√£o automaticamente convertidos para Int64
# Verificar se os parquets de origem est√£o √≠ntegros
```

### ‚úÖ Solu√ß√µes
1. **Verificar caminhos**: Sempre usar caminhos absolutos
2. **Permiss√µes**: Verificar read/write nos diret√≥rios
3. **Espa√ßo em disco**: Manter pelo menos 100GB livres
4. **Depend√™ncias**: Instalar polars, pydantic, etc.

---

## Integra√ß√£o com Outros Sistemas

### üìä Exporta√ß√£o para BI
```python
# Exportar para CSV para ferramentas de BI
processor.export_to_csv(
    input_parquet='/dados/painel.parquet',
    output_csv='/dados/painel_bi.csv',
    delimiter=';'
)
```

### üêç Uso em Scripts
```python
# Integra√ß√£o com pipeline de dados
def pipeline_diario():
    processor = PainelProcessor(config_producao)
    
    if processor.process_complete_painel():
        enviar_para_s3('/dados/painel_dados.parquet')
        notificar_equipe("‚úÖ Painel atualizado")
    else:
        notificar_equipe("‚ùå Falha no processamento")
```

---

## Roadmap

### üîÆ Pr√≥ximas Melhorias
- [ ] Download autom√°tico com requests
- [ ] Processamento distribu√≠do com Dask
- [ ] Cache inteligente de resultados
- [ ] API REST para consultas
- [ ] Dashboard web para monitoramento
- [ ] Integra√ß√£o com Apache Airflow

---

**Desenvolvido para m√°xima efici√™ncia e flexibilidade no processamento de dados da Receita Federal** üáßüá∑ 