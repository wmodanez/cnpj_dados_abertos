"""
Processador de Painel - Combina√ß√£o de Estabelecimento e Simples Nacional.

Este processador implementa o left join entre dados de estabelecimentos
e dados do Simples Nacional, criando uma vis√£o consolidada para exporta√ß√£o.

Funcionalidades:
- Pipeline completo de processamento (download -> ZIP -> parquet -> painel)
- Left join entre estabelecimentos e Simples Nacional por cnpj_basico
- Inner join com dados de empresas
- Aplica√ß√£o de transforma√ß√µes espec√≠ficas da entidade Painel
- Valida√ß√£o de dados combinados
- Gera√ß√£o de campos calculados (situa√ß√µes, formata√ß√µes)
- Suporte a filtros por UF e outros crit√©rios
- Processamento flex√≠vel (ZIPs, parquets existentes, ou pipeline completo)
"""

import logging
import os
import polars as pl
from typing import List, Type, Optional, Dict, Any, Union
from pathlib import Path
import time
import psutil

from ...Entity.Painel import Painel
from ...Entity.base import BaseEntity
from ..base.processor import BaseProcessor

logger = logging.getLogger(__name__)


class PainelProcessor(BaseProcessor):
    """
    Processador espec√≠fico para dados do Painel (Estabelecimento + Simples + Empresa).
    
    Caracter√≠sticas:
    - Pipeline completo de processamento de dados
    - Faz left join entre estabelecimentos e Simples Nacional
    - Inner join com dados de empresas
    - Utiliza entidade Painel para valida√ß√£o e transforma√ß√£o
    - Gera campos calculados √∫teis para exporta√ß√£o
    - Suporte a filtros espec√≠ficos (UF, situa√ß√£o, etc.)
    - Processamento flex√≠vel: ZIPs, parquets existentes, ou pipeline completo
    """
    
    def __init__(self, path_zip: str, path_unzip: str, path_parquet: str, **kwargs):
        """
        Inicializa o processador de Painel.
        
        Args:
            path_zip: Diret√≥rio com arquivos ZIP
            path_unzip: Diret√≥rio para extra√ß√£o
            path_parquet: Diret√≥rio de sa√≠da
            **kwargs: Op√ß√µes espec√≠ficas
                - estabelecimento_path: Caminho para dados de estabelecimentos
                - simples_path: Caminho para dados do Simples Nacional
                - empresa_path: Caminho para dados de empresas
                - situacao_filter: Filtro por situa√ß√£o (opcional)
                - force_reprocess: For√ßar reprocessamento mesmo se parquets existirem
                - skip_download: Pular etapa de download
                - skip_unzip: Pular etapa de descompacta√ß√£o
                - skip_individual_processing: Pular processamento individual
        """
        super().__init__(path_zip, path_unzip, path_parquet, **kwargs)
        
        # Caminhos para dados j√° processados (opcionais)
        self.estabelecimento_path = kwargs.get('estabelecimento_path')
        self.simples_path = kwargs.get('simples_path')
        self.empresa_path = kwargs.get('empresa_path')
        
        # Filtros espec√≠ficos
        self.situacao_filter = kwargs.get('situacao_filter')
        
        # Op√ß√µes de processamento
        self.force_reprocess = kwargs.get('force_reprocess', False)
        self.skip_download = kwargs.get('skip_download', False)
        self.skip_unzip = kwargs.get('skip_unzip', False) 
        self.skip_individual_processing = kwargs.get('skip_individual_processing', False)
        
        # URLs de download (configur√°veis)
        self.download_urls = kwargs.get('download_urls', {
            'estabelecimentos': 'https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos*.zip',
            'simples': 'https://dadosabertos.rfb.gov.br/CNPJ/Simples*.zip',
            'empresas': 'https://dadosabertos.rfb.gov.br/CNPJ/Empresas*.zip'
        })
    
    def get_processor_name(self) -> str:
        """Retorna o nome do processador."""
        return "PAINEL"
    
    def get_entity_class(self) -> Type[BaseEntity]:
        """Retorna a classe de entidade associada."""
        return Painel
    
    def get_valid_options(self) -> List[str]:
        """Retorna op√ß√µes v√°lidas para este processador."""
        return [
            'estabelecimento_path',
            'simples_path', 
            'empresa_path',
            'situacao_filter',
            'force_reprocess',
            'skip_download',
            'skip_unzip',
            'skip_individual_processing'
        ]
    
    def apply_specific_transformations(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        Aplica transforma√ß√µes espec√≠ficas do Painel.
        
        Args:
            df: DataFrame a ser transformado
            
        Returns:
            DataFrame transformado
        """
        try:
            # 1. Garantir que CNPJ b√°sico est√° como bigint (Int64)
            if 'cnpj_basico' in df.columns:
                df = df.with_columns([
                    pl.col('cnpj_basico')
                    .cast(pl.Int64, strict=False)
                    .alias('cnpj_basico')
                ])
            
            # 2. Transformar campos 0/1 em N√£o/Sim
            campos_01 = ['matriz_filial']
            for campo in campos_01:
                if campo in df.columns:
                    df = df.with_columns([
                        pl.when(pl.col(campo) == 1)
                        .then(pl.lit('Sim'))
                        .when(pl.col(campo) == 0)
                        .then(pl.lit('N√£o'))
                        .otherwise(pl.lit('N√£o informado'))
                        .alias(campo)
                    ])
            
            # 3. Transformar campos S/N em Sim/N√£o
            campos_sn = ['opcao_simples', 'opcao_mei']
            for campo in campos_sn:
                if campo in df.columns:
                    df = df.with_columns([
                        pl.when(pl.col(campo) == 'S')
                        .then(pl.lit('Sim'))
                        .when(pl.col(campo) == 'N')
                        .then(pl.lit('N√£o'))
                        .otherwise(pl.lit('N√£o informado'))
                        .alias(campo)
                    ])
            
            # 4. Formatar campos de data para YYYYMMDD
            campos_data = [
                'data_opcao_simples', 'data_exclusao_simples',
                'data_opcao_mei', 'data_exclusao_mei',
                'data_situacao_cadastral', 'data_inicio_atividades'
            ]
            for campo in campos_data:
                if campo in df.columns:
                    df = df.with_columns([
                        pl.col(campo)
                        .str.replace_all(r'[^\d]', '')  # Remove caracteres n√£o num√©ricos
                        .str.pad_start(8, '0')  # Garante 8 d√≠gitos
                        .alias(campo)
                    ])
            
            # 5. Adicionar descri√ß√µes para c√≥digos
            # Porte da empresa
            if 'porte_empresa' in df.columns:
                df = df.with_columns([
                    pl.when(pl.col('porte_empresa') == 1)
                    .then(pl.lit('Micro'))
                    .when(pl.col('porte_empresa') == 2)
                    .then(pl.lit('Pequena'))
                    .when(pl.col('porte_empresa') == 3)
                    .then(pl.lit('M√©dia'))
                    .when(pl.col('porte_empresa') == 4)
                    .then(pl.lit('Grande'))
                    .when(pl.col('porte_empresa') == 5)
                    .then(pl.lit('Demais'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('porte_empresa_descricao')
                ])
            
            # Natureza jur√≠dica
            if 'natureza_juridica' in df.columns:
                df = df.with_columns([
                    pl.when(pl.col('natureza_juridica') == 1)
                    .then(pl.lit('Administra√ß√£o P√∫blica'))
                    .when(pl.col('natureza_juridica') == 2)
                    .then(pl.lit('Entidade Empresarial'))
                    .when(pl.col('natureza_juridica') == 3)
                    .then(pl.lit('Entidade sem Fins Lucrativos'))
                    .when(pl.col('natureza_juridica') == 4)
                    .then(pl.lit('Pessoa F√≠sica'))
                    .when(pl.col('natureza_juridica') == 5)
                    .then(pl.lit('Organiza√ß√£o Internacional'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('natureza_juridica_descricao')
                ])
            
            # C√≥digo motivo
            if 'codigo_motivo' in df.columns:
                df = df.with_columns([
                    pl.when(pl.col('codigo_motivo') == 1)
                    .then(pl.lit('Extin√ß√£o por Encerramento'))
                    .when(pl.col('codigo_motivo') == 2)
                    .then(pl.lit('Incorpora√ß√£o'))
                    .when(pl.col('codigo_motivo') == 3)
                    .then(pl.lit('Fus√£o'))
                    .when(pl.col('codigo_motivo') == 4)
                    .then(pl.lit('Cis√£o'))
                    .when(pl.col('codigo_motivo') == 5)
                    .then(pl.lit('Encerramento de Fal√™ncia'))
                    .when(pl.col('codigo_motivo') == 6)
                    .then(pl.lit('Encerramento de Liquida√ß√£o'))
                    .when(pl.col('codigo_motivo') == 7)
                    .then(pl.lit('Cancelamento de Baixa'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('codigo_motivo_descricao')
                ])
            
            # C√≥digo situa√ß√£o
            if 'codigo_situacao' in df.columns:
                df = df.with_columns([
                    pl.when(pl.col('codigo_situacao') == 1)
                    .then(pl.lit('Nula'))
                    .when(pl.col('codigo_situacao') == 2)
                    .then(pl.lit('Ativa'))
                    .when(pl.col('codigo_situacao') == 3)
                    .then(pl.lit('Suspensa'))
                    .when(pl.col('codigo_situacao') == 4)
                    .then(pl.lit('Inapta'))
                    .when(pl.col('codigo_situacao') == 8)
                    .then(pl.lit('Baixada'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('codigo_situacao_descricao')
                ])
            
            # Tipo situa√ß√£o cadastral
            if 'tipo_situacao_cadastral' in df.columns:
                df = df.with_columns([
                    pl.when(pl.col('tipo_situacao_cadastral') == 1)
                    .then(pl.lit('Ativa'))
                    .when(pl.col('tipo_situacao_cadastral') == 2)
                    .then(pl.lit('Baixa Volunt√°ria'))
                    .when(pl.col('tipo_situacao_cadastral') == 3)
                    .then(pl.lit('Outras Baixas'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('tipo_situacao_cadastral_descricao')
                ])
            
            # 6. Aplicar filtros se especificados explicitamente
            if self.situacao_filter:
                df = df.filter(pl.col('codigo_situacao') == self.situacao_filter)
                self.logger.info(f"Filtro situa√ß√£o aplicado: {self.situacao_filter}")
            
            self.logger.info(f"Transforma√ß√µes espec√≠ficas aplicadas. Registros finais: {df.height}")
            return df
            
        except Exception as e:
            self.logger.error(f"Erro ao aplicar transforma√ß√µes espec√≠ficas: {str(e)}")
            raise
    
    def process_painel_data(self, output_filename: Optional[str] = None) -> bool:
        """
        Processa dados do painel fazendo os joins necess√°rios.
        Usa processamento lazy e em chunks para otimizar uso de mem√≥ria.
        
        Args:
            output_filename: Nome do arquivo de sa√≠da (opcional)
            
        Returns:
            bool: True se processamento foi bem-sucedido
        """
        start_time = time.time()
        join_start_time = None
        
        try:
            self.logger.info("üîÑ === INICIANDO PROCESSAMENTO DO PAINEL ===")
            self.logger.info(f"üìÇ Diret√≥rio de sa√≠da: {os.path.abspath(self.path_parquet)}")
            
            # Validar caminhos de entrada
            if not self.estabelecimento_path or not os.path.exists(self.estabelecimento_path):
                raise ValueError(f"Caminho de estabelecimentos inv√°lido: {self.estabelecimento_path}")
            
            if not self.simples_path or not os.path.exists(self.simples_path):
                raise ValueError(f"Caminho do Simples Nacional inv√°lido: {self.simples_path}")
            
            if not self.empresa_path or not os.path.exists(self.empresa_path):
                raise ValueError(f"Caminho de empresas inv√°lido: {self.empresa_path}")
            
            # 1. Criar scans lazy para os DataFrames
            self.logger.info("üîç Iniciando scans lazy dos dados...")
            
            try:
                # Estabelecimentos
                estabelecimentos_scan = (
                    pl.scan_parquet(f"{self.estabelecimento_path}/*.parquet")
                    if os.path.isdir(self.estabelecimento_path)
                    else pl.scan_parquet(self.estabelecimento_path)
                )
                
                # Simples
                simples_scan = (
                    pl.scan_parquet(f"{self.simples_path}/*.parquet")
                    if os.path.isdir(self.simples_path)
                    else pl.scan_parquet(self.simples_path)
                )
                
                # Empresas
                empresas_scan = (
                    pl.scan_parquet(f"{self.empresa_path}/*.parquet")
                    if os.path.isdir(self.empresa_path)
                    else pl.scan_parquet(self.empresa_path)
                )
                
                # Contar registros sem carregar tudo
                estabelecimentos_count = estabelecimentos_scan.select(pl.count()).collect().item()
                simples_count = simples_scan.select(pl.count()).collect().item()
                empresas_count = empresas_scan.select(pl.count()).collect().item()
                
                self.logger.info(f"‚úì Scans criados:")
                self.logger.info(f"  ‚îî‚îÄ Estabelecimentos: {estabelecimentos_count:,} registros")
                self.logger.info(f"  ‚îî‚îÄ Simples Nacional: {simples_count:,} registros")
                self.logger.info(f"  ‚îî‚îÄ Empresas: {empresas_count:,} registros")
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao criar scans: {str(e)}")
                raise
            
            # 2. Otimizar consultas selecionando apenas colunas necess√°rias
            colunas_estabelecimentos = ['cnpj_basico', 'matriz_filial', 'codigo_situacao', 
                                      'data_situacao_cadastral', 'codigo_motivo', 
                                      'data_inicio_atividades', 'codigo_cnae', 'tipo_situacao_cadastral',
                                      'codigo_municipio']
            
            colunas_simples = ['cnpj_basico', 'opcao_simples', 'data_opcao_simples',
                              'data_exclusao_simples', 'opcao_mei', 'data_opcao_mei',
                              'data_exclusao_mei']
            
            colunas_empresas = ['cnpj_basico', 'natureza_juridica', 'porte_empresa']
            
            # 3. Aplicar transforma√ß√µes em cada dataset separadamente
            self.logger.info("üîÑ Aplicando transforma√ß√µes nos datasets...")
            
            # Transforma√ß√µes em estabelecimentos
            self.logger.info("  ‚îî‚îÄ Transformando estabelecimentos...")
            
            # Verificar se o campo tipo_situacao_cadastral existe e, se n√£o, calcul√°-lo
            try:
                # Verificar se o campo existe nos dados
                colunas_disponiveis = estabelecimentos_scan.collect().limit(1).columns
                
                if 'tipo_situacao_cadastral' not in colunas_disponiveis:
                    self.logger.info("  ‚îî‚îÄ Campo tipo_situacao_cadastral n√£o encontrado, calculando...")
                    
                    # Calcular o campo tipo_situacao_cadastral baseado nas regras de neg√≥cio
                    estabelecimentos_scan = estabelecimentos_scan.with_columns([
                        pl.when(
                            (pl.col('codigo_situacao') == 2) & 
                            (pl.col('codigo_motivo') == 0)
                        )
                        .then(pl.lit(1))  # Ativa
                        .when(
                            (pl.col('codigo_situacao') == 8) & 
                            (pl.col('codigo_motivo') == 1)
                        )
                        .then(pl.lit(2))  # Baixa Volunt√°ria
                        .when(
                            (pl.col('codigo_situacao') == 8) & 
                            (pl.col('codigo_motivo') != 1)
                        )
                        .then(pl.lit(3))  # Outras Baixas
                        .otherwise(pl.lit(0))  # Valor padr√£o para casos n√£o cobertos pelas regras
                        .alias('tipo_situacao_cadastral')
                    ])
                    
                    self.logger.info("  ‚îî‚îÄ Campo tipo_situacao_cadastral calculado com sucesso")
                else:
                    self.logger.info("  ‚îî‚îÄ Campo tipo_situacao_cadastral j√° existe nos dados")
                
            except Exception as e:
                self.logger.warning(f"  ‚îî‚îÄ Erro ao verificar/calcular tipo_situacao_cadastral: {str(e)}")
            
            # Agora selecionar as colunas e aplicar transforma√ß√µes
            estabelecimentos_scan = (
                estabelecimentos_scan
                .select(colunas_estabelecimentos)
                .with_columns([
                    pl.when(pl.col('matriz_filial') == 1)
                    .then(pl.lit('Matriz'))
                    .when(pl.col('matriz_filial') == 2)
                    .then(pl.lit('Filial'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('descricao_matriz_filial'),
                    
                    pl.when(pl.col('codigo_situacao') == 1).then(pl.lit('Nula'))
                    .when(pl.col('codigo_situacao') == 2).then(pl.lit('Ativa'))
                    .when(pl.col('codigo_situacao') == 3).then(pl.lit('Suspensa'))
                    .when(pl.col('codigo_situacao') == 4).then(pl.lit('Inapta'))
                    .when(pl.col('codigo_situacao') == 8).then(pl.lit('Baixada'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('descricao_situacao'),
                    
                    pl.when(pl.col('tipo_situacao_cadastral') == 1).then(pl.lit('Ativa'))
                    .when(pl.col('tipo_situacao_cadastral') == 2).then(pl.lit('Baixa Volunt√°ria'))
                    .when(pl.col('tipo_situacao_cadastral') == 3).then(pl.lit('Outras Baixas'))
                    .otherwise(pl.lit('Outras Situa√ß√µes'))
                    .alias('descricao_tipo_situacao')
                ])
            )
            
            # Adicionar mapeamento de motivo usando a tabela de dom√≠nio
            try:
                motivo_df = pl.read_parquet(os.path.join(os.path.dirname(self.path_parquet), "base", "motivo.parquet"))
                self.logger.info(f"  ‚îî‚îÄ Tabela de motivos carregada: {len(motivo_df)} registros")
                
                # Adicionar coluna com descri√ß√£o usando join com a tabela de motivos
                estabelecimentos_scan = estabelecimentos_scan.with_columns([
                    pl.col('codigo_motivo').cast(pl.Int32).alias('codigo_motivo_join')
                ])
                
                # Criar um LazyFrame da tabela de motivos com apenas as colunas necess√°rias
                motivo_scan = pl.scan_parquet(os.path.join(os.path.dirname(self.path_parquet), "base", "motivo.parquet")).select([
                    pl.col('codigo').alias('codigo_motivo_join'),
                    pl.col('descricao').alias('codigo_motivo_descricao')
                ])
                
                # Join com a tabela de motivos
                estabelecimentos_scan = estabelecimentos_scan.join(
                    motivo_scan,
                    on='codigo_motivo_join',
                    how='left'
                ).drop('codigo_motivo_join')
                
                # Preencher valores nulos com "N√£o informado"
                estabelecimentos_scan = estabelecimentos_scan.with_columns([
                    pl.col('codigo_motivo_descricao').fill_null('N√£o informado').alias('descricao_motivo')
                ]).drop('codigo_motivo_descricao')
                
                self.logger.info("  ‚îî‚îÄ Descri√ß√µes de motivos adicionadas via join")
            except Exception as e:
                self.logger.warning(f"  ‚îî‚îÄ N√£o foi poss√≠vel carregar tabela de motivos: {str(e)}")
                # Fallback para o mapeamento simplificado anterior
                estabelecimentos_scan = estabelecimentos_scan.with_columns([
                    pl.when(pl.col('codigo_motivo') == 1).then(pl.lit('Extin√ß√£o por Encerramento'))
                    .when(pl.col('codigo_motivo') == 2).then(pl.lit('Incorpora√ß√£o'))
                    .when(pl.col('codigo_motivo') == 3).then(pl.lit('Fus√£o'))
                    .when(pl.col('codigo_motivo') == 4).then(pl.lit('Cis√£o'))
                    .when(pl.col('codigo_motivo') == 5).then(pl.lit('Encerramento de Fal√™ncia'))
                    .when(pl.col('codigo_motivo') == 6).then(pl.lit('Encerramento de Liquida√ß√£o'))
                    .when(pl.col('codigo_motivo') == 7).then(pl.lit('Cancelamento de Baixa'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('codigo_motivo_descricao')
                ])
            
            # Transforma√ß√µes em simples
            self.logger.info("  ‚îî‚îÄ Transformando dados do Simples Nacional...")
            simples_scan = (
                simples_scan
                .select(colunas_simples)
                .with_columns([
                    pl.when(pl.col('opcao_simples') == 'S')
                    .then(pl.lit('Sim'))
                    .when(pl.col('opcao_simples') == 'N')
                    .then(pl.lit('N√£o'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('opcao_simples'),
                    
                    pl.when(pl.col('opcao_mei') == 'S')
                    .then(pl.lit('Sim'))
                    .when(pl.col('opcao_mei') == 'N')
                    .then(pl.lit('N√£o'))
                    .otherwise(pl.lit('N√£o informado'))
                    .alias('opcao_mei')
                ])
            )
            
            # Transforma√ß√µes em empresas
            self.logger.info("  ‚îî‚îÄ Transformando dados de empresas...")
            
            # Carregar tabelas de dom√≠nio
            try:
                natureza_juridica_df = pl.read_parquet(os.path.join(os.path.dirname(self.path_parquet), "base", "natureza_juridica.parquet"))
                self.logger.info(f"  ‚îî‚îÄ Tabela de natureza jur√≠dica carregada: {len(natureza_juridica_df)} registros")
                
                # Criar um LazyFrame da tabela de natureza jur√≠dica com apenas as colunas necess√°rias
                natureza_scan = pl.scan_parquet(os.path.join(os.path.dirname(self.path_parquet), "base", "natureza_juridica.parquet")).select([
                    pl.col('codigo').alias('natureza_juridica_join'),
                    pl.col('descricao').alias('descricao_natureza_juridica')
                ])
                
                # Preparar empresas para o join
                empresas_scan = (
                    empresas_scan
                    .select(colunas_empresas)
                    .with_columns([
                        pl.col('natureza_juridica').cast(pl.Int32).alias('natureza_juridica_join'),
                        
                        # Adicionar descri√ß√£o do porte
                        pl.when(pl.col('porte_empresa') == 1).then(pl.lit('Micro'))
                        .when(pl.col('porte_empresa') == 2).then(pl.lit('Pequena'))
                        .when(pl.col('porte_empresa') == 3).then(pl.lit('M√©dia'))
                        .when(pl.col('porte_empresa') == 4).then(pl.lit('Grande'))
                        .when(pl.col('porte_empresa') == 5).then(pl.lit('Demais'))
                        .otherwise(pl.lit('N√£o informado'))
                        .alias('descricao_porte')
                    ])
                )
                
                # Join com a tabela de natureza jur√≠dica
                empresas_scan = empresas_scan.join(
                    natureza_scan,
                    on='natureza_juridica_join',
                    how='left'
                ).drop('natureza_juridica_join')
                
                # Preencher valores nulos com "N√£o informado"
                empresas_scan = empresas_scan.with_columns([
                    pl.col('descricao_natureza_juridica').fill_null('N√£o informado')
                ])
                
                self.logger.info("  ‚îî‚îÄ Descri√ß√µes de natureza jur√≠dica adicionadas via join")
            except Exception as e:
                self.logger.warning(f"  ‚îî‚îÄ N√£o foi poss√≠vel carregar tabela de natureza jur√≠dica: {str(e)}")
                # Fallback para o mapeamento simplificado anterior
                empresas_scan = (
                    empresas_scan
                    .select(colunas_empresas)
                    .with_columns([
                        # Descri√ß√£o do porte
                        pl.when(pl.col('porte_empresa') == 1).then(pl.lit('Micro'))
                        .when(pl.col('porte_empresa') == 2).then(pl.lit('Pequena'))
                        .when(pl.col('porte_empresa') == 3).then(pl.lit('M√©dia'))
                        .when(pl.col('porte_empresa') == 4).then(pl.lit('Grande'))
                        .when(pl.col('porte_empresa') == 5).then(pl.lit('Demais'))
                        .otherwise(pl.lit('N√£o informado'))
                        .alias('descricao_porte'),
                        
                        # Descri√ß√£o da natureza jur√≠dica
                        pl.when(pl.col('natureza_juridica') == 1).then(pl.lit('Administra√ß√£o P√∫blica'))
                        .when(pl.col('natureza_juridica') == 2).then(pl.lit('Entidade Empresarial'))
                        .when(pl.col('natureza_juridica') == 3).then(pl.lit('Entidade sem Fins Lucrativos'))
                        .when(pl.col('natureza_juridica') == 4).then(pl.lit('Pessoa F√≠sica'))
                        .when(pl.col('natureza_juridica') == 5).then(pl.lit('Organiza√ß√£o Internacional'))
                        .otherwise(pl.lit('N√£o informado'))
                        .alias('descricao_natureza_juridica')
                    ])
                )
            
            # 4. Executar JOINs com os dados j√° transformados
            join_start_time = time.time()
            self.logger.info("‚ö° Executando JOINs otimizados...")
            
            try:
                # Primeiro JOIN (estabelecimentos com simples)
                self.logger.info("  ‚îî‚îÄ LEFT JOIN: estabelecimentos + simples")
                self.logger.info("     ‚îî‚îÄ Iniciando JOIN...")
                
                try:
                    painel_scan = estabelecimentos_scan.join(
                        simples_scan,
                        on='cnpj_basico',
                        how='left'
                    )
                    self.logger.info("     ‚îî‚îÄ JOIN estabelecimentos + simples conclu√≠do")
                except Exception as e:
                    self.logger.error(f"‚ùå Erro no JOIN estabelecimentos + simples: {str(e)}")
                    raise
                
                # Segundo JOIN (resultado anterior com empresas)
                self.logger.info("  ‚îî‚îÄ INNER JOIN: resultado anterior + empresas")
                self.logger.info("     ‚îî‚îÄ Iniciando JOIN...")
                
                try:
                    painel_scan = painel_scan.join(
                        empresas_scan,
                        on='cnpj_basico',
                        how='inner'
                    )
                    self.logger.info("     ‚îî‚îÄ JOIN com empresas conclu√≠do")
                except Exception as e:
                    self.logger.error(f"‚ùå Erro no JOIN com empresas: {str(e)}")
                    raise
                
                # Terceiro JOIN (resultado anterior com munic√≠pios)
                self.logger.info("  ‚îî‚îÄ LEFT JOIN: resultado anterior + munic√≠pios")
                self.logger.info("     ‚îî‚îÄ Carregando dados de munic√≠pios...")
                
                try:
                    # Carregar dados de munic√≠pios
                    municipio_path = os.path.join(os.path.dirname(self.path_parquet), "base", "municipio.parquet")
                    if os.path.exists(municipio_path):
                        municipios_df = pl.read_parquet(municipio_path)
                        self.logger.info(f"     ‚îî‚îÄ Munic√≠pios carregados: {len(municipios_df)} registros")
                        
                        # Criar scan dos munic√≠pios com renomea√ß√£o para facilitar o JOIN
                        municipios_scan = pl.scan_parquet(municipio_path).select([
                            pl.col('cod_mn_dados_abertos').alias('codigo_municipio'),  # Renomear para fazer JOIN
                            pl.col('codigo').alias('codigo_ibge'),                     # C√≥digo IBGE (7 d√≠gitos) para exporta√ß√£o
                            pl.col('nome').alias('nome_municipio'),                    # Nome do munic√≠pio
                            pl.col('uf').alias('uf'),                                  # UF do munic√≠pio
                            pl.col('sigla_uf').alias('sigla_uf')                       # Sigla da UF
                        ])
                        
                        # Executar LEFT JOIN com munic√≠pios
                        painel_scan = painel_scan.join(
                            municipios_scan,
                            on='codigo_municipio',
                            how='left'
                        )
                        
                        self.logger.info("     ‚îî‚îÄ LEFT JOIN com munic√≠pios executado")
                        
                    else:
                        self.logger.warning(f"     ‚îî‚îÄ Arquivo de munic√≠pios n√£o encontrado: {municipio_path}")
                        self.logger.warning("     ‚îî‚îÄ Continuando sem c√≥digo IBGE dos munic√≠pios")
                        
                except Exception as e:
                    self.logger.error(f"‚ùå Erro no JOIN com munic√≠pios: {str(e)}")
                    self.logger.warning("‚ö†Ô∏è Continuando processamento sem c√≥digo IBGE dos munic√≠pios")
                
                # 5. Salvar o DataFrame completo
                if not output_filename:
                    output_filename = "painel_dados.parquet"
                
                # Salvar na pasta raiz do parquet
                output_path = os.path.join(self.path_parquet, output_filename)
                output_path_abs = os.path.abspath(output_path)
                
                # Garantir que a pasta existe
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                
                save_start = time.time()
                self.logger.info(f"üíæ Iniciando grava√ß√£o dos dados transformados...")
                
                try:
                    # Reordenar colunas para aproximar c√≥digos e descri√ß√µes
                    colunas_para_selecionar = [
                        # Dados principais
                        'cnpj_basico',
                        
                        # Matriz/Filial
                        'matriz_filial', 'descricao_matriz_filial',
                        
                        # Situa√ß√£o cadastral
                        'codigo_situacao', 'descricao_situacao',
                        'tipo_situacao_cadastral', 'descricao_tipo_situacao',
                        
                        # Motivo
                        'codigo_motivo', 'descricao_motivo',
                        
                        # Datas
                        'data_situacao_cadastral', 'data_inicio_atividades',
                        
                        # CNAE
                        'codigo_cnae',
                        
                        # Natureza jur√≠dica
                        'natureza_juridica', 'descricao_natureza_juridica',
                        
                        # Porte
                        'porte_empresa', 'descricao_porte',
                        
                        # Simples Nacional
                        'opcao_simples', 'data_opcao_simples', 'data_exclusao_simples',
                        'opcao_mei', 'data_opcao_mei', 'data_exclusao_mei',
                        
                        # Localiza√ß√£o
                        'codigo_ibge', 'nome_municipio', 'uf', 'sigla_uf'
                    ]
                    
                    # Selecionar colunas diretamente (vai falhar se n√£o existir, mas isso √© melhor que travar)
                    self.logger.info(f"  ‚îî‚îÄ Selecionando colunas para o resultado final...")
                    
                    try:
                        painel_scan = painel_scan.select(colunas_para_selecionar)
                        self.logger.info(f"  ‚îî‚îÄ {len(colunas_para_selecionar)} colunas selecionadas com sucesso")
                    except Exception as e:
                        self.logger.warning(f"  ‚îî‚îÄ Erro ao selecionar algumas colunas: {str(e)}")
                        # Fallback: selecionar apenas colunas b√°sicas se houver erro
                        colunas_basicas = [
                            'cnpj_basico', 'matriz_filial', 'codigo_situacao', 'data_situacao_cadastral',
                            'codigo_motivo', 'data_inicio_atividades', 'codigo_cnae', 'natureza_juridica',
                            'porte_empresa', 'opcao_simples', 'data_opcao_simples', 'data_exclusao_simples',
                            'opcao_mei', 'data_opcao_mei', 'data_exclusao_mei'
                        ]
                        painel_scan = painel_scan.select(colunas_basicas)
                        self.logger.info(f"  ‚îî‚îÄ Usando sele√ß√£o de fallback com {len(colunas_basicas)} colunas b√°sicas")
                    
                    # Usar sink_parquet para salvar diretamente sem coletar tudo na mem√≥ria
                    self.logger.info(f"  ‚îî‚îÄ Salvando arquivo: {output_path_abs}")
                    
                    # Configurar op√ß√µes de escrita otimizadas
                    write_options = {
                        "compression": "zstd",  # Compress√£o eficiente
                        "statistics": True,     # Coletar estat√≠sticas
                        "row_group_size": 100000  # Tamanho do grupo de linhas
                    }
                    
                    # Usar sink_parquet para salvar diretamente sem carregar tudo na mem√≥ria
                    self.logger.info("  ‚îî‚îÄ Salvando arquivo parquet diretamente (sem carregar na mem√≥ria)...")
                    try:
                        painel_scan.sink_parquet(output_path, **write_options)
                    except Exception as e:
                        self.logger.error(f"‚ùå Erro ao salvar com sink_parquet: {str(e)}")
                        self.logger.info("  ‚îî‚îÄ Tentando salvamento alternativo com collect em chunks...")
                        
                        # M√©todo alternativo: processar em chunks
                        chunk_size = 1_000_000  # 1 milh√£o de registros por chunk
                        
                        # Primeiro, contar total de registros
                        total_rows = painel_scan.select(pl.count()).collect().item()
                        self.logger.info(f"  ‚îî‚îÄ Total de registros a processar: {total_rows:,}")
                        
                        # Processar em chunks
                        num_chunks = (total_rows + chunk_size - 1) // chunk_size
                        self.logger.info(f"  ‚îî‚îÄ Processando em {num_chunks} chunks de {chunk_size:,} registros")
                        
                        first_chunk = True
                        for i in range(num_chunks):
                            offset = i * chunk_size
                            self.logger.info(f"  ‚îî‚îÄ Processando chunk {i+1}/{num_chunks} (offset: {offset:,})")
                            
                            chunk_df = painel_scan.slice(offset, chunk_size).collect()
                            
                            if first_chunk:
                                # Primeiro chunk: criar arquivo
                                chunk_df.write_parquet(output_path, **write_options)
                                first_chunk = False
                            else:
                                # Chunks subsequentes: anexar ao arquivo existente
                                existing_df = pl.read_parquet(output_path)
                                combined_df = pl.concat([existing_df, chunk_df])
                                combined_df.write_parquet(output_path, **write_options)
                                del combined_df, existing_df  # Liberar mem√≥ria
                            
                            del chunk_df  # Liberar mem√≥ria do chunk
                            
                        self.logger.info("  ‚îî‚îÄ Salvamento em chunks conclu√≠do")
                        
                        # For√ßar coleta de lixo
                        import gc
                        gc.collect()
                    
                    self.logger.info("  ‚îî‚îÄ Arquivo salvo com sucesso")
                    
                    save_time = time.time() - save_start
                    total_time = time.time() - start_time
                    
                    # Verificar arquivo final
                    if not os.path.exists(output_path):
                        raise FileNotFoundError(f"Arquivo n√£o foi criado: {output_path}")
                    
                    file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
                    
                    self.logger.info("\n=== üéâ PROCESSAMENTO DO PAINEL CONCLU√çDO COM SUCESSO ===")
                    self.logger.info(f"üìÇ Arquivo salvo em: {output_path_abs}")
                    self.logger.info(f"üìä Tamanho do arquivo: {file_size:.1f}MB")
                    
                    # Contar registros apenas se arquivo n√£o for muito grande (para evitar problemas de mem√≥ria)
                    if file_size < 1000:  # Menos de 1GB
                        try:
                            total_rows = pl.scan_parquet(output_path).select(pl.count()).collect().item()
                            self.logger.info(f"üìà Total de registros: {total_rows:,}")
                        except Exception as e:
                            self.logger.warning(f"N√£o foi poss√≠vel contar registros: {str(e)}")
                    else:
                        self.logger.info("üìà Arquivo muito grande - contagem de registros pulada para evitar problemas de mem√≥ria")
                    
                    self.logger.info("\n‚è±Ô∏è  Tempos de processamento:")
                    self.logger.info(f"  ‚îî‚îÄ Processamento e JOINs: {save_start - join_start_time:.1f}s")
                    self.logger.info(f"  ‚îî‚îÄ Salvamento: {save_time:.1f}s")
                    self.logger.info(f"  ‚îî‚îÄ TEMPO TOTAL: {total_time:.1f}s ({total_time/60:.1f}min)")
                    self.logger.info("================================================")
                    
                    return True
                    
                except Exception as e:
                    self.logger.error(f"‚ùå Erro ao salvar dados: {str(e)}")
                    self.logger.error("Detalhes do erro:", exc_info=True)
                    raise
                
            except Exception as e:
                total_time = time.time() - start_time
                join_time = time.time() - join_start_time if join_start_time else 0
                
                self.logger.error("\n=== ‚ùå ERRO NO PROCESSAMENTO DO PAINEL ===")
                self.logger.error(f"Erro: {str(e)}")
                self.logger.error(f"Tempo decorrido at√© o erro: {total_time:.1f}s")
                if join_start_time:
                    self.logger.error(f"Tempo em opera√ß√µes de JOIN: {join_time:.1f}s")
                self.logger.error("Stacktrace completo:", exc_info=True)
                self.logger.error("==========================================")
                return False
            
        except Exception as e:
            total_time = time.time() - start_time
            join_time = time.time() - join_start_time if join_start_time else 0
            
            self.logger.error("\n=== ‚ùå ERRO NO PROCESSAMENTO DO PAINEL ===")
            self.logger.error(f"Erro: {str(e)}")
            self.logger.error(f"Tempo decorrido at√© o erro: {total_time:.1f}s")
            if join_start_time:
                self.logger.error(f"Tempo em opera√ß√µes de JOIN: {join_time:.1f}s")
            self.logger.error("Stacktrace:", exc_info=True)
            self.logger.error("==========================================")
            return False
    
    def _generate_statistics_report(self, df: pl.DataFrame):
        """Gera relat√≥rio de estat√≠sticas dos dados processados."""
        try:
            self.logger.info("=== RELAT√ìRIO DE ESTAT√çSTICAS DO PAINEL ===")
            
            # Estat√≠sticas gerais
            total_registros = df.height
            self.logger.info(f"Total de registros: {total_registros:,}")
            
            # Estat√≠sticas de op√ß√£o pelo Simples Nacional
            if 'opcao_simples' in df.columns:
                simples_stats = df.group_by('opcao_simples').agg([
                    pl.count().alias('count')
                ]).sort('count', descending=True)
                
                self.logger.info("Op√ß√£o pelo Simples Nacional:")
                for row in simples_stats.iter_rows(named=True):
                    opcao = 'Sim' if row['opcao_simples'] == 'S' else 'N√£o' if row['opcao_simples'] == 'N' else 'N√£o informado'
                    pct = (row['count'] / total_registros) * 100
                    self.logger.info(f"  {opcao}: {row['count']:,} ({pct:.1f}%)")
            
            # Estat√≠sticas de op√ß√£o pelo MEI
            if 'opcao_mei' in df.columns:
                mei_stats = df.group_by('opcao_mei').agg([
                    pl.count().alias('count')
                ]).sort('count', descending=True)
                
                self.logger.info("Op√ß√£o pelo MEI:")
                for row in mei_stats.iter_rows(named=True):
                    opcao = 'Sim' if row['opcao_mei'] == 'S' else 'N√£o' if row['opcao_mei'] == 'N' else 'N√£o informado'
                    pct = (row['count'] / total_registros) * 100
                    self.logger.info(f"  {opcao}: {row['count']:,} ({pct:.1f}%)")
            
            # Estat√≠sticas de matriz/filial
            if 'matriz_filial' in df.columns:
                matriz_filial_stats = df.group_by('matriz_filial').agg([
                    pl.count().alias('count')
                ]).sort('count', descending=True)
                
                self.logger.info("Tipo de estabelecimento:")
                for row in matriz_filial_stats.iter_rows(named=True):
                    tipo = 'Matriz' if row['matriz_filial'] == 1 else 'Filial' if row['matriz_filial'] == 2 else 'Indefinido'
                    pct = (row['count'] / total_registros) * 100
                    self.logger.info(f"  {tipo}: {row['count']:,} ({pct:.1f}%)")
            
            # Estat√≠sticas de situa√ß√£o cadastral
            if 'codigo_situacao' in df.columns:
                situacao_stats = df.group_by('codigo_situacao').agg([
                    pl.count().alias('count')
                ]).sort('count', descending=True)
                
                self.logger.info("Situa√ß√£o cadastral:")
                for row in situacao_stats.iter_rows(named=True):
                    situacao_map = {1: 'Nula', 2: 'Ativa', 3: 'Suspensa', 4: 'Inapta', 8: 'Baixada'}
                    situacao = situacao_map.get(row['codigo_situacao'], 'Outros')
                    pct = (row['count'] / total_registros) * 100
                    self.logger.info(f"  {situacao}: {row['count']:,} ({pct:.1f}%)")
            
            # Estat√≠sticas de porte da empresa
            if 'porte_empresa' in df.columns:
                porte_stats = df.group_by('porte_empresa').agg([
                    pl.count().alias('count')
                ]).sort('count', descending=True)
                
                self.logger.info("Porte da empresa:")
                for row in porte_stats.iter_rows(named=True):
                    porte_map = {1: 'Micro', 2: 'Pequena', 3: 'M√©dia', 4: 'Grande', 5: 'Demais'}
                    porte = porte_map.get(row['porte_empresa'], 'N√£o informado')
                    pct = (row['count'] / total_registros) * 100
                    self.logger.info(f"  {porte}: {row['count']:,} ({pct:.1f}%)")
            
            self.logger.info("=== FIM DO RELAT√ìRIO ===")
            
        except Exception as e:
            self.logger.error(f"Erro ao gerar relat√≥rio de estat√≠sticas: {str(e)}")
    
    def process_single_zip_impl(self, zip_file: str, path_zip: str, path_unzip: str, path_parquet: str, **kwargs) -> bool:
        """
        Implementa√ß√£o para compatibilidade com BaseProcessor.
        
        Para o PainelProcessor, este m√©todo delega para process_painel_data()
        j√° que n√£o processamos ZIPs diretamente, mas sim dados j√° processados.
        """
        return self.process_painel_data()
    
    def export_to_csv(self, input_parquet: str, output_csv: str, delimiter: str = ';') -> bool:
        """
        Exporta dados do painel para CSV.
        
        Args:
            input_parquet: Caminho do arquivo parquet
            output_csv: Caminho do arquivo CSV de sa√≠da
            delimiter: Delimitador para o CSV
            
        Returns:
            bool: True se exporta√ß√£o foi bem-sucedida
        """
        try:
            self.logger.info(f"Exportando dados para CSV: {output_csv}")
            
            # Carregar dados
            df = pl.read_parquet(input_parquet)
            
            # Exportar para CSV
            df.write_csv(output_csv, separator=delimiter)
            
            self.logger.info(f"‚úì Exporta√ß√£o para CSV conclu√≠da: {df.height} registros")
            return True
            
        except Exception as e:
            self.logger.error(f"Erro na exporta√ß√£o para CSV: {str(e)}")
            return False
    
    def process_complete_painel(self, output_filename: Optional[str] = None) -> bool:
        """
        Processa dados do painel de forma completa desde o download at√© o painel final.
        
        Este m√©todo executa todo o pipeline:
        1. Download dos arquivos (se necess√°rio)
        2. Descompacta√ß√£o (se necess√°rio) 
        3. Processamento individual das entidades (se necess√°rio)
        4. Cria√ß√£o do painel combinado
        5. Aplica√ß√£o de filtros e transforma√ß√µes
        6. Gera√ß√£o do arquivo final
        
        Args:
            output_filename: Nome do arquivo de sa√≠da (opcional)
            
        Returns:
            bool: True se processamento foi bem-sucedido
        """
        try:
            self.logger.info("=== INICIANDO PROCESSAMENTO COMPLETO DO PAINEL ===")
            
            # Etapa 1: Verificar estado atual dos dados
            estado_dados = self._verificar_estado_dados()
            self.logger.info(f"Estado atual dos dados: {estado_dados}")
            
            # Etapa 2: Download (se necess√°rio)
            if not self.skip_download and estado_dados['precisa_download']:
                self.logger.info("Iniciando download dos arquivos...")
                if not self._executar_downloads():
                    self.logger.error("Falha no download dos arquivos")
                    return False
                self.logger.info("‚úì Downloads conclu√≠dos")
            
            # Etapa 3: Descompacta√ß√£o (se necess√°rio)
            if not self.skip_unzip and estado_dados['precisa_unzip']:
                self.logger.info("Iniciando descompacta√ß√£o dos arquivos...")
                if not self._executar_descompactacao():
                    self.logger.error("Falha na descompacta√ß√£o")
                    return False
                self.logger.info("‚úì Descompacta√ß√£o conclu√≠da")
            
            # Etapa 4: Processamento individual das entidades (se necess√°rio)
            if not self.skip_individual_processing and estado_dados['precisa_processamento']:
                self.logger.info("Iniciando processamento individual das entidades...")
                if not self._executar_processamento_individual():
                    self.logger.error("Falha no processamento individual")
                    return False
                self.logger.info("‚úì Processamento individual conclu√≠do")
            
            # Etapa 5: Definir caminhos dos parquets
            if not self._definir_caminhos_parquets():
                self.logger.error("Falha ao definir caminhos dos parquets")
                return False
            
            # Etapa 6: Criar painel combinado
            self.logger.info("Iniciando cria√ß√£o do painel combinado...")
            if not self.process_painel_data(output_filename):
                self.logger.error("Falha na cria√ß√£o do painel")
                return False
            
            self.logger.info("=== PROCESSAMENTO COMPLETO DO PAINEL CONCLU√çDO ===")
            return True
            
        except Exception as e:
            self.logger.error(f"Erro no processamento completo do painel: {str(e)}")
            return False
    
    def _verificar_estado_dados(self) -> Dict[str, bool]:
        """
        Verifica o estado atual dos dados e determina quais etapas s√£o necess√°rias.
        
        Returns:
            Dict com flags indicando quais etapas s√£o necess√°rias
        """
        estado = {
            'precisa_download': False,
            'precisa_unzip': False,
            'precisa_processamento': False,
            'tem_parquets': False
        }
        
        try:
            # Verificar se h√° parquets j√° processados
            parquets_paths = {
                'estabelecimento': self.estabelecimento_path or os.path.join(self.path_parquet, 'estabelecimento'),
                'simples': self.simples_path or os.path.join(self.path_parquet, 'simples'),
                'empresa': self.empresa_path or os.path.join(self.path_parquet, 'empresa')
            }
            
            parquets_existem = all(
                os.path.exists(path) and self._tem_arquivos_parquet(path)
                for path in parquets_paths.values()
            )
            
            if parquets_existem and not self.force_reprocess:
                estado['tem_parquets'] = True
                self.logger.info("Parquets j√° existem, usando dados processados")
                return estado
            
            # Verificar se h√° arquivos CSV descompactados
            csvs_existem = self._verificar_csvs_descompactados()
            if csvs_existem and not self.force_reprocess:
                estado['precisa_processamento'] = True
                self.logger.info("CSVs descompactados encontrados")
                return estado
            
            # Verificar se h√° arquivos ZIP
            zips_existem = self._verificar_zips_disponiveis()
            if zips_existem:
                estado['precisa_unzip'] = True
                estado['precisa_processamento'] = True
                self.logger.info("Arquivos ZIP encontrados")
                return estado
            
            # Precisa baixar tudo
            estado['precisa_download'] = True
            estado['precisa_unzip'] = True
            estado['precisa_processamento'] = True
            self.logger.info("Nenhum dado encontrado, ser√° necess√°rio download completo")
            
            return estado
            
        except Exception as e:
            self.logger.error(f"Erro ao verificar estado dos dados: {str(e)}")
            # Em caso de erro, assumir que precisa de tudo
            return {
                'precisa_download': True,
                'precisa_unzip': True,
                'precisa_processamento': True,
                'tem_parquets': False
            }
    
    def _tem_arquivos_parquet(self, path: str) -> bool:
        """Verifica se um diret√≥rio tem arquivos parquet."""
        if not os.path.exists(path):
            return False
        
        if os.path.isfile(path) and path.endswith('.parquet'):
            return True
        
        if os.path.isdir(path):
            parquet_files = [f for f in os.listdir(path) if f.endswith('.parquet')]
            return len(parquet_files) > 0
        
        return False
    
    def _verificar_csvs_descompactados(self) -> bool:
        """Verifica se h√° CSVs descompactados dispon√≠veis."""
        if not os.path.exists(self.path_unzip):
            return False
        
        # Procurar por padr√µes de arquivos esperados
        padroes = ['*ESTABELE*', '*SIMPLES*', '*EMPRESAS*']
        
        for padrao in padroes:
            import glob
            files = glob.glob(os.path.join(self.path_unzip, f"{padrao}.csv"))
            if not files:
                return False
        
        return True
    
    def _verificar_zips_disponiveis(self) -> bool:
        """Verifica se h√° arquivos ZIP dispon√≠veis."""
        if not os.path.exists(self.path_zip):
            return False
        
        # Procurar por padr√µes de arquivos ZIP esperados
        padroes = ['*Estabele*', '*Simples*', '*Empresas*']
        
        for padrao in padroes:
            import glob
            files = glob.glob(os.path.join(self.path_zip, f"{padrao}*.zip"))
            if not files:
                return False
        
        return True
    
    def _executar_downloads(self) -> bool:
        """
        Executa o download dos arquivos necess√°rios.
        
        Returns:
            bool: True se download foi bem-sucedido
        """
        try:
            # Criar diret√≥rio de download se n√£o existir
            os.makedirs(self.path_zip, exist_ok=True)
            
            # Implementar download dos arquivos
            # Nota: Esta √© uma implementa√ß√£o simplificada
            # Em produ√ß√£o, seria necess√°rio implementar download real
            
            self.logger.info("Download dos arquivos (implementa√ß√£o seria necess√°ria)")
            
            # Por enquanto, assumir que os arquivos j√° est√£o dispon√≠veis
            # Em implementa√ß√£o real, usar requests ou urllib para download
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erro no download: {str(e)}")
            return False
    
    def _executar_descompactacao(self) -> bool:
        """
        Executa a descompacta√ß√£o dos arquivos ZIP.
        
        Returns:
            bool: True se descompacta√ß√£o foi bem-sucedida
        """
        try:
            import zipfile
            import glob
            
            # Criar diret√≥rio de descompacta√ß√£o
            os.makedirs(self.path_unzip, exist_ok=True)
            
            # Encontrar todos os arquivos ZIP
            zip_files = glob.glob(os.path.join(self.path_zip, "*.zip"))
            
            if not zip_files:
                self.logger.error("Nenhum arquivo ZIP encontrado")
                return False
            
            for zip_file in zip_files:
                self.logger.info(f"Descompactando: {os.path.basename(zip_file)}")
                
                with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                    zip_ref.extractall(self.path_unzip)
                
                self.logger.info(f"‚úì Descompactado: {os.path.basename(zip_file)}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erro na descompacta√ß√£o: {str(e)}")
            return False
    
    def _executar_processamento_individual(self) -> bool:
        """
        Executa o processamento individual das entidades.
        
        Returns:
            bool: True se processamento foi bem-sucedido
        """
        try:
            # Criar diret√≥rio de parquets
            os.makedirs(self.path_parquet, exist_ok=True)
            
            # Importar processadores necess√°rios
            from .estabelecimento_processor import EstabelecimentoProcessor
            from .simples_processor import SimplesProcessor
            from .empresa_processor import EmpresaProcessor
            
            processadores = [
                ('estabelecimento', EstabelecimentoProcessor),
                ('simples', SimplesProcessor),
                ('empresa', EmpresaProcessor)
            ]
            
            for nome, ProcessorClass in processadores:
                self.logger.info(f"Processando {nome}...")
                
                # Criar subdiret√≥rio para cada entidade
                output_path = os.path.join(self.path_parquet, nome)
                os.makedirs(output_path, exist_ok=True)
                
                # Inicializar processador
                processor = ProcessorClass(
                    path_zip=self.path_zip,
                    path_unzip=self.path_unzip,
                    path_parquet=output_path
                )
                
                # Processar arquivos ZIP
                import glob
                zip_pattern = self._get_zip_pattern(nome)
                zip_files = glob.glob(os.path.join(self.path_zip, zip_pattern))
                
                if not zip_files:
                    self.logger.error(f"Nenhum arquivo ZIP encontrado para {nome}")
                    return False
                
                for zip_file in zip_files:
                    if not processor.process_single_zip_impl(
                        zip_file=os.path.basename(zip_file),
                        path_zip=self.path_zip,
                        path_unzip=self.path_unzip,
                        path_parquet=output_path
                    ):
                        self.logger.error(f"Falha no processamento de {zip_file}")
                        return False
                
                self.logger.info(f"‚úì {nome} processado com sucesso")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Erro no processamento individual: {str(e)}")
            return False
    
    def _get_zip_pattern(self, entidade: str) -> str:
        """Retorna o padr√£o de arquivo ZIP para uma entidade."""
        patterns = {
            'estabelecimento': '*Estabele*.zip',
            'simples': '*Simples*.zip',
            'empresa': '*Empresas*.zip'
        }
        return patterns.get(entidade, '*.zip')
    
    def _definir_caminhos_parquets(self) -> bool:
        """
        Define os caminhos dos parquets baseado no que est√° dispon√≠vel.
        
        Returns:
            bool: True se caminhos foram definidos com sucesso
        """
        try:
            # Se caminhos j√° foram especificados, usar eles
            if not self.estabelecimento_path:
                self.estabelecimento_path = os.path.join(self.path_parquet, 'estabelecimento')
            
            if not self.simples_path:
                self.simples_path = os.path.join(self.path_parquet, 'simples')
            
            if not self.empresa_path:
                self.empresa_path = os.path.join(self.path_parquet, 'empresa')
            
            # Verificar se todos os caminhos existem
            caminhos = [self.estabelecimento_path, self.simples_path, self.empresa_path]
            nomes = ['estabelecimento', 'simples', 'empresa']
            
            for caminho, nome in zip(caminhos, nomes):
                if not self._tem_arquivos_parquet(caminho):
                    self.logger.error(f"Parquets de {nome} n√£o encontrados em: {caminho}")
                    return False
            
            self.logger.info("‚úì Caminhos dos parquets definidos com sucesso")
            return True
            
        except Exception as e:
            self.logger.error(f"Erro ao definir caminhos dos parquets: {str(e)}")
            return False


# ===== EXEMPLOS DE USO =====

def exemplo_processamento_completo():
    """
    Exemplo de uso do processador completo do painel.
    
    Este exemplo mostra como processar dados do painel desde o download
    at√© a cria√ß√£o do arquivo final.
    """
    
    # Configura√ß√£o b√°sica de caminhos
    config = {
        'path_zip': '/caminho/para/zips',
        'path_unzip': '/caminho/para/extrair',
        'path_parquet': '/caminho/para/parquets',
        
        # Filtros opcionais
        'situacao_filter': 2,  # Apenas estabelecimentos ativos
        
        # Op√ß√µes de processamento
        'force_reprocess': False,  # N√£o reprocessar se parquets existirem
        'skip_download': False,    # Executar download se necess√°rio
        'skip_unzip': False,       # Executar descompacta√ß√£o se necess√°rio
        'skip_individual_processing': False  # Processar entidades individuais
    }
    
    # Criar processador
    processor = PainelProcessor(**config)
    
    # Executar processamento completo
    sucesso = processor.process_complete_painel(output_filename='painel_sp_ativos.parquet')
    
    if sucesso:
        print("‚úì Processamento do painel conclu√≠do com sucesso!")
    else:
        print("‚úó Falha no processamento do painel")


def exemplo_uso_parquets_existentes():
    """
    Exemplo de uso com parquets j√° processados.
    
    Este exemplo mostra como criar o painel quando j√° se tem
    os parquets das entidades individuais.
    """
    
    config = {
        'path_zip': '/caminho/para/zips',  # N√£o ser√° usado
        'path_unzip': '/caminho/para/extrair',  # N√£o ser√° usado  
        'path_parquet': '/caminho/para/saida',
        
        # Caminhos espec√≠ficos para dados j√° processados
        'estabelecimento_path': '/dados/estabelecimentos.parquet',
        'simples_path': '/dados/simples.parquet',
        'empresa_path': '/dados/empresas.parquet',
        
        # Pular etapas desnecess√°rias
        'skip_download': True,
        'skip_unzip': True,
        'skip_individual_processing': True
    }
    
    processor = PainelProcessor(**config)
    
    # Processar apenas o painel (sem pipeline completo)
    sucesso = processor.process_painel_data(output_filename='painel_rj.parquet')
    
    if sucesso:
        print("‚úì Painel criado com sucesso a partir de parquets existentes!")


def exemplo_uso_flexivel():
    """
    Exemplo de uso flex√≠vel baseado no estado dos dados.
    
    O processador detecta automaticamente o que est√° dispon√≠vel
    e executa apenas as etapas necess√°rias.
    """
    
    config = {
        'path_zip': '/dados/zips',
        'path_unzip': '/dados/temp',
        'path_parquet': '/dados/output',
        
        # N√£o especificar caminhos individuais - deixar o processador decidir
        # 'estabelecimento_path': None,
        # 'simples_path': None, 
        # 'empresa_path': None,
        
        # Permitir que o processador decida o que fazer
        'force_reprocess': False,
        
        # Filtros aplicados apenas no painel final
        'situacao_filter': None  # Todas as situa√ß√µes
    }
    
    processor = PainelProcessor(**config)
    
    # O processador vai:
    # 1. Verificar se existem parquets -> usar se existirem
    # 2. Se n√£o, verificar CSVs -> processar se existirem  
    # 3. Se n√£o, verificar ZIPs -> descompactar e processar
    # 4. Se n√£o, fazer download -> descompactar e processar
    
    sucesso = processor.process_complete_painel()
    
    return sucesso


# ===== UTILIT√ÅRIOS PARA AN√ÅLISE =====

def analisar_painel(caminho_parquet: str):
    """
    Utilit√°rio para analisar dados do painel gerado.
    
    Args:
        caminho_parquet: Caminho para o arquivo parquet do painel
    """
    try:
        import polars as pl
        
        # Carregar dados
        df = pl.read_parquet(caminho_parquet)
        
        print(f"=== AN√ÅLISE DO PAINEL ===")
        print(f"Total de registros: {df.height:,}")
        print(f"Total de colunas: {df.width}")
        
        # Estat√≠sticas gerais
        total_registros = df.height
        print(f"Total de registros: {total_registros:,}")
        
        # Estat√≠sticas de op√ß√£o pelo Simples Nacional
        if 'opcao_simples' in df.columns:
            simples_stats = df.group_by('opcao_simples').agg([
                pl.count().alias('count')
            ])
            
            print("\nOp√ß√£o pelo Simples Nacional:")
            for row in simples_stats.iter_rows(named=True):
                opcao = 'Sim' if row['opcao_simples'] == 'S' else 'N√£o' if row['opcao_simples'] == 'N' else 'N√£o informado'
                pct = (row['count'] / df.height) * 100
                print(f"  {opcao}: {row['count']:,} ({pct:.1f}%)")
        
        # Estat√≠sticas de porte
        if 'porte_empresa' in df.columns:
            porte_stats = df.group_by('porte_empresa').agg([
                pl.count().alias('count')
            ])
            
            print("\nPorte da empresa:")
            porte_map = {1: 'Micro', 2: 'Pequena', 3: 'M√©dia', 4: 'Grande', 5: 'Demais'}
            for row in porte_stats.iter_rows(named=True):
                porte = porte_map.get(row['porte_empresa'], 'N√£o informado')
                pct = (row['count'] / df.height) * 100
                print(f"  {porte}: {row['count']:,} ({pct:.1f}%)")
        
        print("=== FIM DA AN√ÅLISE ===")
        
    except Exception as e:
        print(f"Erro na an√°lise: {str(e)}")


if __name__ == "__main__":
    # Exemplo de execu√ß√£o
    print("Exemplo de processamento completo do painel:")
    exemplo_processamento_completo() 